# -*- coding: utf-8 -*-
"""
è¯´æ˜ï¼š
- æœ¬è„šæœ¬æ˜¯åŸºäºç”¨æˆ·æä¾›çš„ä¸¤ä¸ªç‰ˆæœ¬èåˆã€ä¿®å¤å’Œä¼˜åŒ–åçš„æœ€ç»ˆç‰ˆæœ¬ã€‚
- æ ¸å¿ƒç›®æ ‡ï¼šä¿®å¤ç¾åŒ–ç‰ˆä¸­å¤å……ç‡æ•°æ®ä¸¢å¤±çš„bugï¼Œå¹¶é‡‡çº³å…¶ä¼˜ç§€çš„Excel/HTMLæ ¼å¼åŒ–è¾“å‡ºåŠŸèƒ½ã€‚
- ä¿®å¤å…³é”®ç‚¹ï¼š
  1. ä¿®æ­£äº†`calculate_metrics`å‡½æ•°ï¼Œç¡®ä¿åœ¨è®¡ç®—åç”¨0å¡«å……æ‰€æœ‰ç©ºå€¼(NaN)ï¼Œé˜²æ­¢é”™è¯¯ä¼ é€’ã€‚
  2. é‡‡ç”¨äº†ç‰ˆæœ¬ä¸€ä¸­ç»è¿‡éªŒè¯çš„ã€æ›´ç®€æ´çš„å¤å……ç‡åˆå¹¶é€»è¾‘åˆ°æ—¥æŠ¥ç”Ÿæˆå‡½æ•°`generate_summary_df`ä¸­ã€‚
- æ ¼å¼ä¼˜åŒ–ï¼š
  1. é‡‡çº³äº†ç”¨æˆ·è¦æ±‚ï¼Œå°†è¾“å‡ºæ–‡ä»¶åæ ¼å¼ä¿®æ”¹ä¸º `YYYYMMDD_äº§å“å_ç»¼åˆæŠ¥è¡¨.xlsx/.html`ã€‚
  2. å†…éƒ¨æ ‡é¢˜å’ŒSheeté¡µæ ‡é¢˜ä¿æŒäº† `äº§å“å - æŠ¥è¡¨ç±»å‹ - æ—¥æœŸ` çš„æ¸…æ™°ç»“æ„ã€‚
"""
import pandas as pd
import glob
import os
import numpy as np
import sys
from datetime import datetime, timedelta, date
import warnings
from pandas.errors import SettingWithCopyWarning
from dateutil.relativedelta import relativedelta
import calendar

warnings.filterwarnings("ignore", category=SettingWithCopyWarning)

# ==================== é…ç½®åŒº ====================
EXCHANGE_RATE = 281
PRODUCT_NAME = "aa-å·´åŸºæ–¯å¦(EpiWin)"
# Google Sheet æ¶ˆè€—æ•°æ®é“¾æ¥
SPEND_SHEET_URL = "https://docs.google.com/spreadsheets/d/1v_GQLJ28byHFUqfcvdo2OtAbLQaMOCBL9x7Q-MqkjmI/export?format=csv"
# å¦‚æœéœ€è¦å¼ºåˆ¶æŒ‡å®šä¸€ä¸ªæŠ¥è¡¨æ—¥æœŸ (æ ¼å¼: "YYYY-MM-DD")ï¼Œè¯·åœ¨è¿™é‡Œå¡«å†™ã€‚ç•™ç©ºåˆ™è‡ªåŠ¨ä½¿ç”¨æœ€æ–°æ—¥æœŸã€‚
OVERRIDE_DATE = "2025-10-5"
# ===============================================


# ==================== è¾“å‡ºå­—æ®µå®šä¹‰ ====================
PRODUCT_COLS = [
    'æ—¥æœŸ', 'äº§å“', 'æ€»æ¶ˆè€—(U)', 'æ³¨å†Œæˆæœ¬', 'é¦–å……æˆæœ¬', 'æ–°å¢ç”¨æˆ·æ•°', 'å……å€¼äººæ•°', 'å……å€¼é‡‘é¢(U)', 'æç°é‡‘é¢(U)',
    'å……å‡æ(U)', 'ç›ˆä½™ç‡(%)', 'é¦–å­˜äººæ•°', 'é¦–å­˜å……å€¼é‡‘é¢(U)', 'é¦–å­˜ä»˜è´¹ç‡(%)',
    'é¦–å­˜ARPPU', 'æ–°å¢ä»˜è´¹äººæ•°', 'æ–°å¢å……å€¼é‡‘é¢(U)', 'æ–°å¢ä»˜è´¹ç‡(%)', 'è€ç”¨æˆ·å……å€¼äººæ•°',
    'è€ç”¨æˆ·å……å€¼é‡‘é¢(U)', 'è€ç”¨æˆ·ä»˜è´¹ç‡(%)', 'è€ç”¨æˆ·ARPPU', 'è€ç”¨æˆ·ç›ˆä½™ç‡(%)', 'ARPPU',
    'æ¬¡æ—¥å¤å……ç‡(%)', '3æ—¥å¤å……ç‡(%)', '7æ—¥å¤å……ç‡(%)', '15æ—¥å¤å……ç‡(%)', '30æ—¥å¤å……ç‡(%)',
    'LTV-7å¤©', 'LTV-15å¤©', 'LTV-30å¤©', 'è£‚å˜ç‡'
]
DEPT_COLS = [
    'æ—¥æœŸ', 'éƒ¨é—¨', 'æ€»æ¶ˆè€—(U)', 'æ³¨å†Œæˆæœ¬', 'é¦–å……æˆæœ¬', 'æ–°å¢ç”¨æˆ·æ•°', 'å……å€¼äººæ•°', 'å……å€¼é‡‘é¢(U)', 'æç°é‡‘é¢(U)',
    'å……å‡æ(U)', 'ç›ˆä½™ç‡(%)', 'é¦–å­˜äººæ•°', 'é¦–å­˜å……å€¼é‡‘é¢(U)', 'é¦–å­˜ä»˜è´¹ç‡(%)',
    'é¦–å­˜ARPPU', 'æ–°å¢ä»˜è´¹äººæ•°', 'æ–°å¢å……å€¼é‡‘é¢(U)', 'æ–°å¢ä»˜è´¹ç‡(%)', 'è€ç”¨æˆ·å……å€¼äººæ•°',
    'è€ç”¨æˆ·å……å€¼é‡‘é¢(U)', 'è€ç”¨æˆ·ä»˜è´¹ç‡(%)', 'è€ç”¨æˆ·ARPPU', 'è€ç”¨æˆ·ç›ˆä½™ç‡(%)', 'ARPPU',
    'æ¬¡æ—¥å¤å……ç‡(%)', '3æ—¥å¤å……ç‡(%)', '7æ—¥å¤å……ç‡(%)', '15æ—¥å¤å……ç‡(%)', '30æ—¥å¤å……ç‡(%)',
    'LTV-7å¤©', 'LTV-15å¤©', 'LTV-30å¤©', 'è€ç”¨æˆ·å……å‡æ(U)', 'è€ç©å®¶æ—¥æ´»'
]
CHANNEL_COLS = [
    'æ—¥æœŸ', 'éƒ¨é—¨', 'æ¸ é“æ¥æº', 'æ€»æ¶ˆè€—(U)', 'æ³¨å†Œæˆæœ¬', 'é¦–å……æˆæœ¬', 'æ–°å¢ç”¨æˆ·æ•°', 'å……å€¼äººæ•°', 'å……å€¼é‡‘é¢(U)',
    'æç°é‡‘é¢(U)', 'å……å‡æ(U)', 'ç›ˆä½™ç‡(%)', 'é¦–å­˜äººæ•°', 'é¦–å­˜å……å€¼é‡‘é¢(U)', 'é¦–å­˜ä»˜è´¹ç‡(%)',
    'é¦–å­˜ARPPU', 'æ–°å¢ä»˜è´¹äººæ•°', 'æ–°å¢å……å€¼é‡‘é¢(U)', 'æ–°å¢ä»˜è´¹ç‡(%)', 'è€ç”¨æˆ·å……å€¼äººæ•°',
    'è€ç”¨æˆ·å……å€¼é‡‘é¢(U)', 'è€ç”¨æˆ·ä»˜è´¹ç‡(%)', 'è€ç”¨æˆ·ARPPU', 'è€ç”¨æˆ·ç›ˆä½™ç‡(%)', 'ARPPU',
    'æ¬¡æ—¥å¤å……ç‡(%)', '3æ—¥å¤å……ç‡(%)', '7æ—¥å¤å……ç‡(%)', '15æ—¥å¤å……ç‡(%)', '30æ—¥å¤å……ç‡(%)',
    'LTV-7å¤©', 'LTV-15å¤©', 'LTV-30å¤©', 'è€ç”¨æˆ·å……å‡æ(U)', 'è€ç©å®¶æ—¥æ´»'
]
PRODUCT_REPORT_COLS = [
    'å‘¨æœŸ', 'å§‹æ—¥-æœ«æœŸ', 'æ€»æ¶ˆè€—(U)', 'æ³¨å†Œæˆæœ¬', 'é¦–å……æˆæœ¬', 'æ–°å¢ç”¨æˆ·æ•°', 'å……å€¼äººæ•°', 'å……å€¼é‡‘é¢(U)', 'æç°é‡‘é¢(U)',
    'å……å‡æ(U)', 'ç›ˆä½™ç‡(%)', 'é¦–å­˜äººæ•°', 'é¦–å­˜å……å€¼é‡‘é¢(U)', 'é¦–å­˜ä»˜è´¹ç‡(%)', 'é¦–å­˜ç›ˆä½™ç‡(%)', 'é¦–å­˜ARPPU',
    'æ–°å¢ä»˜è´¹äººæ•°', 'æ–°å¢å……å€¼é‡‘é¢(U)', 'æ–°å¢ä»˜è´¹ç‡(%)', 'è€ç”¨æˆ·å……å€¼äººæ•°', 'è€ç”¨æˆ·å……å€¼é‡‘é¢(U)',
    'è€ç”¨æˆ·ä»˜è´¹ç‡(%)', 'è€ç”¨æˆ·ARPPU', 'è€ç”¨æˆ·ç›ˆä½™ç‡(%)', 'ARPPU', 'æ¬¡æ—¥å¤å……ç‡(%)', '3æ—¥å¤å……ç‡(%)',
    '7æ—¥å¤å……ç‡(%)', '15æ—¥å¤å……ç‡(%)', '30æ—¥å¤å……ç‡(%)', 'LTV-7å¤©', 'LTV-15å¤©', 'LTV-30å¤©', 'è£‚å˜ç‡',
    'è€ç”¨æˆ·å……å‡æ(U)', 'è€ç©å®¶æ—¥æ´»', 'å†å²æ¶ˆè€—', 'å†å²å……æå·®'
]
PRODUCT_MONTHLY_COLS_PREFIX = ['å¼€å§‹', 'ç»“æŸ']
PRODUCT_MONTHLY_REPORT_COLS = PRODUCT_MONTHLY_COLS_PREFIX + PRODUCT_REPORT_COLS


# ==================== æ™ºèƒ½æ–‡ä»¶è¯»å–ä¸è¯Šæ–­å‡½æ•° ====================
def find_and_read_file(directory, pattern, is_critical=False, file_description=""):
    search_path = os.path.join(directory, pattern)
    files = glob.glob(search_path)

    if not files:
        message = f"æœªæ‰¾åˆ°æ–‡ä»¶: {pattern}"
        if is_critical:
            print(f"[è‡´å‘½é”™è¯¯] {file_description}ç¼ºå¤±, æ— æ³•ç»§ç»­ã€‚æœŸæœ›è·¯å¾„: {search_path}")
            print("\n" + "=" * 20 + " [è‡ªåŠ¨è¯Šæ–­ä¿¡æ¯] " + "=" * 20)
            print(f"ç¨‹åºåœ¨ä»¥ä¸‹ç›®å½•ä¸­æ‰¾ä¸åˆ°æ‰€éœ€æ–‡ä»¶:\n  {directory}")
            print("è¯·æ£€æŸ¥ä¸‹é¢çš„æ–‡ä»¶åˆ—è¡¨ï¼Œç¡®è®¤æ‚¨çš„æ–‡ä»¶åä¸ç¨‹åºæœŸæœ›çš„åç§°å®Œå…¨ä¸€è‡´ï¼ˆåŒ…æ‹¬æ‰©å±•å .csvï¼‰ã€‚\n")
            try:
                print("å½“å‰ç›®å½•ä¸‹çš„æ–‡ä»¶å’Œæ–‡ä»¶å¤¹åˆ—è¡¨:")
                found_items = False
                for item in os.listdir(directory):
                    print(f"  - {item}")
                    found_items = True
                if not found_items:
                    print("  (è¯¥ç›®å½•ä¸ºç©º)")
            except Exception as e:
                print(f"  æ— æ³•åˆ—å‡ºç›®å½•å†…å®¹: {e}")
            print("\nå¸¸è§é—®é¢˜ï¼š")
            print("  1. æ–‡ä»¶åæœ‰æ‹¼å†™é”™è¯¯ã€åŒ…å«äº†å¤šä½™çš„ç©ºæ ¼ã€‚")
            print("  2. æ–‡ä»¶çš„æ‰©å±•åä¸æ˜¯'.csv' (ä¾‹å¦‚, å®ƒå¯èƒ½æ˜¯'.xlsx'æˆ–å¤§å†™çš„'.CSV')ã€‚")
            print("  3. æ–‡ä»¶åä¸ä»£ç ä¸­çš„'æ€»ä»£åç§°éƒ¨é—¨è§„å¾‹è¡¨.csv'ä¸å®Œå…¨åŒ¹é…ã€‚")
            print("=" * 65 + "\n")
            sys.exit()
        else:
            print(f"  [è­¦å‘Š] {message}")
            return None

    latest_file = max(files, key=os.path.getctime)
    print(f"  æ­£åœ¨è¯»å–: {os.path.basename(latest_file)}")

    df = None
    try:
        is_excel = False
        if latest_file.endswith('.csv'):
            with open(latest_file, 'rb') as f:
                try:
                    if f.read(4) == b'PK\x03\x04': is_excel = True
                except:
                    pass

        if is_excel or latest_file.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(latest_file)
        elif latest_file.endswith('.csv'):
            encodings = ['utf-8-sig', 'utf-8', 'gbk', 'latin1', 'ISO-8851-1']
            for encoding in encodings:
                try:
                    df = pd.read_csv(latest_file, encoding=encoding, sep=None, header=0, on_bad_lines='warn',
                                     engine='python')
                    if df.shape[1] > 1:
                        print(f"  [è¯Šæ–­] ä½¿ç”¨'{encoding}'ç¼–ç æˆåŠŸè§£æã€‚")
                        break
                    else:
                        df = None
                except Exception:
                    continue

        if df is not None:
            df.columns = df.columns.str.strip()
            print(f"  [æˆåŠŸ] æ–‡ä»¶å·²è¯»å–å¹¶æ¸…ç†åˆ—åã€‚")
            return df
        else:
            raise ValueError("æ‰€æœ‰è§£æå°è¯•å‡å¤±è´¥ã€‚")

    except Exception as e:
        message = f"è¯»å–æ–‡ä»¶ {os.path.basename(latest_file)} æ—¶å‡ºé”™: {e}"
        if is_critical:
            print(f"[è‡´å‘½é”™è¯¯] {message}")
            sys.exit()
        else:
            print(f"  [è­¦å‘Š] {message}")
            return None


# ==================== æŠ¥è¡¨ç¾åŒ–ä¸è¾“å‡ºæ ¸å¿ƒ ====================

def write_tables_to_sheet(writer, sheet_name, reports_dict, main_title):
    """å°†å¤šä¸ªæŠ¥è¡¨å­—å…¸å†™å…¥åŒä¸€ä¸ªsheet, å‚ç›´æ’åˆ—, å¹¶æ·»åŠ ä¸»æ ‡é¢˜ã€‚"""
    workbook = writer.book
    worksheet = workbook.add_worksheet(sheet_name)
    writer.sheets[sheet_name] = worksheet

    # --- å®šä¹‰æ ¼å¼ ---
    master_title_format = workbook.add_format(
        {'bold': True, 'font_size': 18, 'font_name': 'ç­‰çº¿', 'align': 'left', 'valign': 'vcenter'})
    header_format = workbook.add_format({
        'bold': True, 'font_size': 11, 'font_name': 'Arial', 'align': 'center', 'valign': 'vcenter',
        'fg_color': '#FCE4D6', 'border': 1, 'border_color': '#FFC000'
    })
    table_title_format = workbook.add_format(
        {'bold': True, 'font_size': 14, 'font_name': 'ç­‰çº¿', 'align': 'left', 'valign': 'vcenter'})

    cell_format_odd = workbook.add_format(
        {'border': 1, 'font_name': 'Arial', 'font_size': 10, 'border_color': '#FFC000'})
    cell_format_even = workbook.add_format(
        {'border': 1, 'font_name': 'Arial', 'font_size': 10, 'fg_color': '#FDF2EA', 'border_color': '#FFC000'})

    p_odd_format = workbook.add_format(
        {'border': 1, 'font_name': 'Arial', 'font_size': 10, 'num_format': '0.00%', 'border_color': '#FFC000'})
    p_even_format = workbook.add_format(
        {'border': 1, 'font_name': 'Arial', 'font_size': 10, 'fg_color': '#FDF2EA', 'num_format': '0.00%',
         'border_color': '#FFC000'})

    c_odd_format = workbook.add_format(
        {'border': 1, 'font_name': 'Arial', 'font_size': 10, 'num_format': '#,##0.00', 'border_color': '#FFC000'})
    c_even_format = workbook.add_format(
        {'border': 1, 'font_name': 'Arial', 'font_size': 10, 'fg_color': '#FDF2EA', 'num_format': '#,##0.00',
         'border_color': '#FFC000'})

    i_odd_format = workbook.add_format(
        {'border': 1, 'font_name': 'Arial', 'font_size': 10, 'num_format': '#,##0', 'border_color': '#FFC000'})
    i_even_format = workbook.add_format(
        {'border': 1, 'font_name': 'Arial', 'font_size': 10, 'fg_color': '#FDF2EA', 'num_format': '#,##0',
         'border_color': '#FFC000'})

    red_font_format = workbook.add_format({'font_color': '#FF0000'})

    # --- å†™å…¥ä¸»æ ‡é¢˜ ---
    worksheet.set_row(0, 30)
    worksheet.merge_range(0, 0, 0, 10, main_title, master_title_format)

    current_row = 2
    for title, df in reports_dict.items():
        if df.empty: continue

        worksheet.set_row(current_row, 25)
        worksheet.merge_range(current_row, 0, current_row, 10, f'â–  {title}', table_title_format)
        current_row += 1

        for col_num, value in enumerate(df.columns.values):
            worksheet.write(current_row, col_num, value, header_format)

        for row_idx, row_data in enumerate(df.itertuples(index=False)):
            data_row = current_row + 1 + row_idx
            is_even_row = (row_idx % 2 == 1)

            for col_idx, cell_value in enumerate(row_data):
                col_name = df.columns[col_idx]

                if '(%)' in col_name or 'ç‡' in col_name or 'ç¯æ¯”' in col_name:
                    current_format = p_even_format if is_even_row else p_odd_format
                elif '(U)' in col_name or any(s in col_name for s in ['æˆæœ¬', 'ARPPU', 'LTV', 'æ¶ˆè€—', 'å·®', 'é‡‘é¢']):
                    current_format = c_even_format if is_even_row else c_odd_format
                elif isinstance(cell_value, (int, float, np.number)):
                    current_format = i_even_format if is_even_row else i_odd_format
                else:
                    current_format = cell_format_even if is_even_row else cell_format_odd

                worksheet.write(data_row, col_idx, cell_value, current_format)

        data_end_row = current_row + len(df)
        worksheet.conditional_format(current_row + 1, 0, data_end_row, len(df.columns) - 1, {
            'type': 'cell', 'criteria': '<', 'value': 0, 'format': red_font_format
        })

        current_row += len(df) + 3

    worksheet.autofit()


def export_reports_to_html(filename, daily_reports, weekly_reports, monthly_reports, report_date_str):
    """ç”ŸæˆåŒ…å«æ‰€æœ‰æŠ¥è¡¨çš„å•ä¸ªHTMLæ–‡ä»¶, ç”¨äºæ‰“å°æˆ–è½¬ä¸ºPDFã€‚"""

    def format_df_for_html(df):
        df_html = df.copy()
        for col in df_html.columns:
            if pd.api.types.is_numeric_dtype(df_html[col]):
                if '(%)' in col or 'ç‡' in col or 'ç¯æ¯”' in col:
                    df_html[col] = pd.to_numeric(df_html[col], errors='coerce').apply(
                        lambda x: f'<span style="color:red;">{x:.2%}</span>' if x < 0 else f'{x:.2%}' if pd.notna(
                            x) else '')
                elif '(U)' in col or any(s in col for s in ['æˆæœ¬', 'ARPPU', 'LTV', 'æ¶ˆè€—', 'å·®', 'é‡‘é¢']):
                    df_html[col] = pd.to_numeric(df_html[col], errors='coerce').apply(
                        lambda x: f'<span style="color:red;">{x:,.2f}</span>' if x < 0 else f'{x:,.2f}' if pd.notna(
                            x) else '')
                elif df_html[col].dtype in ['int64', 'float64']:
                    df_html[col] = pd.to_numeric(df_html[col], errors='coerce').apply(
                        lambda x: f'<span style="color:red;">{x:,.0f}</span>' if x < 0 else f'{x:,.0f}' if pd.notna(
                            x) else '')
        return df_html

    html = f"""
    <html>
    <head>
        <meta charset="UTF-8">
        <title>{PRODUCT_NAME} - ç»¼åˆæŠ¥è¡¨ - {report_date_str}</title>
        <style>
            body {{ font-family: 'Segoe UI', 'Microsoft YaHei', sans-serif; margin: 20px; }}
            .main-title {{ color: #000; font-size: 2em; text-align: center; margin-bottom: 20px; }}
            h1 {{ color: #333; border-bottom: 2px solid #D99694; padding-bottom: 10px; font-size: 1.5em; }}
            h2 {{ color: #C0504D; font-size: 1.2em; margin-top: 30px; }}
            table {{ border-collapse: collapse; width: 100%; margin-top: 15px; font-size: 0.9em; }}
            th, td {{ border: 1px solid #F3BBB8; padding: 8px; text-align: right; }}
            th {{ background-color: #FCE4D6; font-weight: bold; }}
            tr:nth-child(even) {{ background-color: #FDF2EA; }}
            @media print {{ body {{ -webkit-print-color-adjust: exact; }} h1, h2 {{ page-break-after: avoid; }} table {{ page-break-inside: auto; }} }}
        </style>
    </head>
    <body>
    <div class="main-title">{PRODUCT_NAME} - ç»¼åˆæŠ¥è¡¨ - {report_date_str}</div>
    """

    report_sections = {"æ—¥æŠ¥": daily_reports, "å‘¨æŠ¥": weekly_reports, "æœˆæŠ¥": monthly_reports}

    for section_title, reports in report_sections.items():
        html += f"<h1>{PRODUCT_NAME} - {section_title} - {report_date_str}</h1>"
        for report_title, df in reports.items():
            if not df.empty:
                html += f"<h2>{report_title}</h2>"
                df_formatted = format_df_for_html(df)
                html += df_formatted.to_html(index=False, escape=False)

    html += "</body></html>"

    with open(filename, 'w', encoding='utf-8') as f:
        f.write(html)


# ==================== æ•°æ®è®¡ç®—ä¸å¤„ç† ====================
def map_and_aggregate(df, df_mapping, value_cols, weight_col):
    if df is None or df.empty or df_mapping is None: return pd.DataFrame()
    mapping_dict = {row.iloc[1]: row.iloc[0] for _, row in df_mapping.iterrows()}

    def map_channel_to_dept(channel):
        for keyword, dept in mapping_dict.items():
            if keyword in str(channel): return dept
        return 'unknown'

    df['éƒ¨é—¨'] = df.iloc[:, 1].apply(map_channel_to_dept)

    unmapped_channels = df[df['éƒ¨é—¨'] == 'unknown'].iloc[:, 1].unique()
    if len(unmapped_channels) > 0:
        print("\n" + "=" * 20 + " [é…ç½®è­¦å‘Š] " + "=" * 20)
        print(f"  ä»¥ä¸‹æ¸ é“/æ¥æºåœ¨'æ€»ä»£åç§°éƒ¨é—¨è§„å¾‹è¡¨.csv'ä¸­æ‰¾ä¸åˆ°åŒ¹é…çš„éƒ¨é—¨ï¼Œå°†è¢«å½’å…¥'unknown'ï¼š")
        for channel in unmapped_channels:
            print(f"    - {channel}")
        print("  è¿™å¯èƒ½å¯¼è‡´ã€éƒ¨é—¨-æ—¥æŠ¥ã€‘å’Œã€æ¸ é“-æ—¥æŠ¥ã€‘ä¸­çš„å¤å……ç‡ç­‰æ•°æ®ä¸º0ã€‚")
        print("  è¯·æ£€æŸ¥æ‚¨çš„æ˜ å°„è¡¨ï¼Œä¸ºè¿™äº›æ¸ é“/æ¥æºæ·»åŠ æ­£ç¡®çš„éƒ¨é—¨æ˜ å°„ã€‚")
        print("=" * 65 + "\n")

    for col in value_cols:
        if col in df.columns:
            df[f'weighted_{col}'] = pd.to_numeric(df[col], errors='coerce').fillna(0) * pd.to_numeric(df[weight_col],
                                                                                                      errors='coerce').fillna(
                0)
    agg_dict = {f'weighted_{col}': 'sum' for col in value_cols if f'weighted_{col}' in df.columns}
    agg_dict[weight_col] = 'sum'
    dept_summary = df.groupby('éƒ¨é—¨').agg(agg_dict).reset_index()
    for col in value_cols:
        if f'weighted_{col}' in dept_summary.columns and dept_summary[weight_col].sum() > 0:
            avg_rate = dept_summary[f'weighted_{col}'] / dept_summary[weight_col].replace(0, np.nan)
            dept_summary[col] = avg_rate / 100.0
    return dept_summary[['éƒ¨é—¨'] + value_cols].fillna(0)


def read_and_process_recharge_data(df_recharge_source, df_mapping, report_date):
    print("--- æ­£åœ¨ä¸ºæ—¥æŠ¥å¤„ç†ã€é¦–å……ç”¨æˆ·åˆ†æã€‘æ•°æ® ---")
    if df_recharge_source is None or df_recharge_source.empty: return pd.DataFrame(), pd.Series(dtype=float)

    df_recharge = df_recharge_source.copy()
    if 'é¦–å……äººæ•°' in df_recharge.columns:
        df_recharge.rename(columns={'é¦–å……äººæ•°': 'é¦–å­˜äººæ•°'}, inplace=True)

    rate_map = {'æ¬¡æ—¥å¤å……ç‡(%)': 1, '3æ—¥å¤å……ç‡(%)': 3, '7æ—¥å¤å……ç‡(%)': 7, '15æ—¥å¤å……ç‡(%)': 15, '30æ—¥å¤å……ç‡(%)': 30}
    all_dept_rates = []
    total_rates = {}

    for rate_col, days_back in rate_map.items():
        if rate_col not in df_recharge.columns: continue

        target_date = report_date - timedelta(days=days_back)
        cohort_data = df_recharge[df_recharge['æ—¥æœŸ'] == target_date].copy()

        if not cohort_data.empty:
            cohort_data[rate_col] = pd.to_numeric(cohort_data[rate_col], errors='coerce').fillna(0)
            cohort_data['é¦–å­˜äººæ•°'] = pd.to_numeric(cohort_data['é¦–å­˜äººæ•°'], errors='coerce').fillna(0)

            weighted_sum = (cohort_data[rate_col] * cohort_data['é¦–å­˜äººæ•°']).sum()
            total_users = cohort_data['é¦–å­˜äººæ•°'].sum()
            avg_rate = weighted_sum / total_users if total_users > 0 else 0
            total_rates[rate_col] = avg_rate / 100.0

            dept_rates = map_and_aggregate(cohort_data, df_mapping, [rate_col], 'é¦–å­˜äººæ•°')
            all_dept_rates.append(dept_rates)
        else:
            total_rates[rate_col] = 0

    if not all_dept_rates:
        return pd.DataFrame(), pd.Series(total_rates)

    final_dept_df = all_dept_rates[0]
    for df in all_dept_rates[1:]:
        if not df.empty: final_dept_df = pd.merge(final_dept_df, df, on='éƒ¨é—¨', how='outer')

    print("--- æ—¥æŠ¥å¤å……ç‡æ•°æ®å¤„ç†å®Œæˆ ---\n")
    return final_dept_df.fillna(0), pd.Series(total_rates)


def get_spend_data_from_google_sheet(url):
    print("æ­£åœ¨ä»Google Sheeté“¾æ¥è¯»å–'æ¶ˆè€—'æ•°æ®...")
    try:
        df = pd.read_csv(url);
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], format='%Y%m%d').dt.date
        spend_cols = [col for col in df.columns if col not in ['æ—¥æœŸ', 'å’Œ', 'å¤‡æ³¨']]
        for col in spend_cols: df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        df['æ€»æ¶ˆè€—(U)'] = df[spend_cols].sum(axis=1);
        return df[['æ—¥æœŸ', 'æ€»æ¶ˆè€—(U)']]
    except Exception as e:
        print(f"  [é”™è¯¯] è‡ªåŠ¨è¯»å–Google Sheetå¤±è´¥: {e}"); return None


def calculate_metrics(df):
    df = df.copy()
    currency_cols = ['å……å€¼é‡‘é¢', 'æç°é‡‘é¢', 'é¦–å­˜å……å€¼é‡‘é¢', 'è€ç”¨æˆ·å……å€¼é‡‘é¢', 'æ–°å¢å……å€¼é‡‘é¢', 'è€ç”¨æˆ·æç°é‡‘é¢']
    for col in currency_cols:
        if col in df.columns: df[f'{col}(U)'] = pd.to_numeric(df[col], errors='coerce').fillna(0) / EXCHANGE_RATE
    with np.errstate(divide='ignore', invalid='ignore'):
        df['å……å‡æ(U)'] = df.get('å……å€¼é‡‘é¢(U)', 0) - df.get('æç°é‡‘é¢(U)', 0)
        df['è€ç”¨æˆ·å……å‡æ(U)'] = df.get('è€ç”¨æˆ·å……å€¼é‡‘é¢(U)', 0) - df.get('è€ç”¨æˆ·æç°é‡‘é¢(U)', 0)
        cols_to_ensure = ['æ€»æ¶ˆè€—(U)', 'æ–°å¢ç”¨æˆ·æ•°', 'é¦–å­˜äººæ•°', 'è€ç”¨æˆ·å……å€¼äººæ•°', 'è€ç©å®¶æ—¥æ´»', 'å……å€¼äººæ•°',
                          'æ–°å¢ä»˜è´¹äººæ•°']
        for col in cols_to_ensure:
            if col not in df.columns:
                df[col] = 0
            else:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        df['æ³¨å†Œæˆæœ¬'] = df['æ€»æ¶ˆè€—(U)'] / df['æ–°å¢ç”¨æˆ·æ•°'];
        df['é¦–å……æˆæœ¬'] = df['æ€»æ¶ˆè€—(U)'] / df['é¦–å­˜äººæ•°']
        df['ç›ˆä½™ç‡(%)'] = df['å……å‡æ(U)'] / df['å……å€¼é‡‘é¢(U)'];
        df['è€ç”¨æˆ·ç›ˆä½™ç‡(%)'] = df['è€ç”¨æˆ·å……å‡æ(U)'] / df['è€ç”¨æˆ·å……å€¼é‡‘é¢(U)']
        df['è€ç”¨æˆ·ä»˜è´¹ç‡(%)'] = df['è€ç”¨æˆ·å……å€¼äººæ•°'] / df['è€ç©å®¶æ—¥æ´»']
        df['é¦–å­˜ä»˜è´¹ç‡(%)'] = df['é¦–å­˜äººæ•°'] / df['æ–°å¢ç”¨æˆ·æ•°']
        df['æ–°å¢ä»˜è´¹ç‡(%)'] = df['æ–°å¢ä»˜è´¹äººæ•°'] / df['æ–°å¢ç”¨æˆ·æ•°'];
        df['é¦–å­˜ARPPU'] = df['é¦–å­˜å……å€¼é‡‘é¢(U)'] / df['é¦–å­˜äººæ•°']
        df['è€ç”¨æˆ·ARPPU'] = df['è€ç”¨æˆ·å……å€¼é‡‘é¢(U)'] / df['è€ç”¨æˆ·å……å€¼äººæ•°'];
        df['ARPPU'] = df['å……å€¼é‡‘é¢(U)'] / df['å……å€¼äººæ•°']
        df['é¦–å­˜ç›ˆä½™ç‡(%)'] = 0
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    df.fillna(0, inplace=True)  # [å…³é”®ä¿®å¤] ç¡®ä¿åœ¨æ‰€æœ‰è®¡ç®—åï¼Œç”¨0å¡«å……NaNï¼Œé˜²æ­¢é”™è¯¯ä¼ é€’
    return df


# ==================== æŠ¥è¡¨ç”Ÿæˆå‡½æ•° ====================

def calculate_period_repurchase_rates(df_recharge_source, period_start_date, period_end_date):
    if df_recharge_source is None or df_recharge_source.empty: return {}
    df_recharge = df_recharge_source.copy()
    if 'é¦–å……äººæ•°' in df_recharge.columns: df_recharge.rename(columns={'é¦–å……äººæ•°': 'é¦–å­˜äººæ•°'}, inplace=True)
    if 'æ—¥æœŸ' not in df_recharge.columns or 'é¦–å­˜äººæ•°' not in df_recharge.columns: return {}

    rate_map = {'æ¬¡æ—¥å¤å……ç‡(%)': 1, '3æ—¥å¤å……ç‡(%)': 3, '7æ—¥å¤å……ç‡(%)': 7, '15æ—¥å¤å……ç‡(%)': 15, '30æ—¥å¤å……ç‡(%)': 30}
    calculated_rates = {}

    for rate_col, _ in rate_map.items():
        if rate_col not in df_recharge.columns: continue
        period_cohort_data = df_recharge[
            (df_recharge['æ—¥æœŸ'] >= period_start_date) & (df_recharge['æ—¥æœŸ'] <= period_end_date)
            ].copy()
        if period_cohort_data.empty:
            calculated_rates[rate_col] = 0;
            continue
        period_cohort_data['é¦–å­˜äººæ•°'] = pd.to_numeric(period_cohort_data['é¦–å­˜äººæ•°'], errors='coerce').fillna(0)
        period_cohort_data[rate_col] = pd.to_numeric(period_cohort_data[rate_col], errors='coerce').fillna(0)
        period_cohort_data['weighted_rate'] = period_cohort_data[rate_col] * period_cohort_data['é¦–å­˜äººæ•°']
        total_weighted_rate = period_cohort_data['weighted_rate'].sum()
        total_weight = period_cohort_data['é¦–å­˜äººæ•°'].sum()
        avg_rate = total_weighted_rate / total_weight if total_weight > 0 else 0
        calculated_rates[rate_col] = avg_rate / 100.0
    return calculated_rates


def aggregate_and_calculate_period(df_period, all_historical_data, start_date, end_date, df_recharge_source):
    if df_period.empty: return pd.DataFrame()
    df_summary = pd.DataFrame(df_period.sum(numeric_only=True)).T
    df_summary = calculate_metrics(df_summary)

    for days in [7, 15, 30]:
        window_start_date = start_date;
        window_end_date = start_date + timedelta(days=days - 1)
        window_df = all_historical_data[
            (all_historical_data['æ—¥æœŸ'] >= window_start_date) & (all_historical_data['æ—¥æœŸ'] <= window_end_date) &
            (all_historical_data['æ—¥æœŸ'] <= end_date)
            ]
        total_recharge = window_df['å……å€¼é‡‘é¢(U)'].sum()
        total_new_users = df_period['æ–°å¢ç”¨æˆ·æ•°'].sum()
        df_summary[f'LTV-{days}å¤©'] = total_recharge / total_new_users if total_new_users else 0

    history_to_end = all_historical_data[all_historical_data['æ—¥æœŸ'] <= end_date]
    df_summary['å†å²æ¶ˆè€—'] = history_to_end['æ€»æ¶ˆè€—(U)'].sum()
    df_summary['å†å²å……æå·®'] = history_to_end['å……å‡æ(U)'].sum()

    period_rates = calculate_period_repurchase_rates(df_recharge_source, start_date, end_date)
    if period_rates:
        for col, value in period_rates.items():
            df_summary[col] = value
    return df_summary


def generate_product_weekly_report(all_historical_data, report_date, df_recharge_source):
    print("--- æ­£åœ¨ç”Ÿæˆã€äº§å“-å‘¨æŠ¥ã€‘æ•°æ® ---")
    this_week_start = report_date - timedelta(days=report_date.weekday())
    this_week_end = this_week_start + timedelta(days=6)
    last_week_start = this_week_start - timedelta(days=7)
    last_week_end = this_week_start - timedelta(days=1)

    df_this_week = all_historical_data[
        (all_historical_data['æ—¥æœŸ'] >= this_week_start) & (all_historical_data['æ—¥æœŸ'] <= this_week_end)]
    df_last_week = all_historical_data[
        (all_historical_data['æ—¥æœŸ'] >= last_week_start) & (all_historical_data['æ—¥æœŸ'] <= last_week_end)]

    row_this_week = aggregate_and_calculate_period(df_this_week, all_historical_data, this_week_start, this_week_end,
                                                   df_recharge_source)
    row_last_week = aggregate_and_calculate_period(df_last_week, all_historical_data, last_week_start, last_week_end,
                                                   df_recharge_source)

    if row_this_week.empty: row_this_week = pd.DataFrame(
        columns=row_last_week.columns if not row_last_week.empty else PRODUCT_REPORT_COLS, index=[0]).fillna(0)
    if row_last_week.empty: row_last_week = pd.DataFrame(columns=row_this_week.columns, index=[0]).fillna(0)

    row_this_week_numeric = row_this_week.apply(pd.to_numeric, errors='coerce').iloc[0]
    row_last_week_numeric = row_last_week.apply(pd.to_numeric, errors='coerce').iloc[0]
    row_diff = row_this_week_numeric - row_last_week_numeric
    with np.errstate(divide='ignore', invalid='ignore'):
        row_wow = (row_this_week_numeric - row_last_week_numeric) / row_last_week_numeric.replace(0, np.nan)

    df_final = pd.DataFrame(columns=PRODUCT_REPORT_COLS)
    data_map = {'ä¸Šå‘¨': row_last_week.iloc[0], 'æœ¬å‘¨': row_this_week.iloc[0], 'æ•°å·®': row_diff, 'ç¯æ¯”': row_wow}
    date_ranges = {'ä¸Šå‘¨': f"{last_week_start.strftime('%m/%d')}-{last_week_end.strftime('%m/%d')}",
                   'æœ¬å‘¨': f"{this_week_start.strftime('%m/%d')}-{this_week_end.strftime('%m/%d')}",
                   'æ•°å·®': 'æœ¬å‘¨-ä¸Šå‘¨', 'ç¯æ¯”': 'æœ¬å‘¨/ä¸Šå‘¨-1'}
    for period, data_row in data_map.items():
        new_row = {'å‘¨æœŸ': period, 'å§‹æ—¥-æœ«æœŸ': date_ranges[period]}
        for col in PRODUCT_REPORT_COLS:
            if col in data_row.index: new_row[col] = data_row[col]
        df_final = pd.concat([df_final, pd.DataFrame([new_row])], ignore_index=True)

    return df_final[PRODUCT_REPORT_COLS].fillna(0)


def generate_product_monthly_report(all_historical_data, report_date, df_recharge_source):
    print("--- æ­£åœ¨ç”Ÿæˆã€äº§å“-æœˆæŠ¥ã€‘æ•°æ® ---")
    report_list = []
    for i in range(4):
        target_month_date = report_date - relativedelta(months=i)
        start_of_month = target_month_date.replace(day=1)
        end_of_month = target_month_date.replace(
            day=calendar.monthrange(target_month_date.year, target_month_date.month)[1])
        df_month = all_historical_data[
            (all_historical_data['æ—¥æœŸ'] >= start_of_month) & (all_historical_data['æ—¥æœŸ'] <= end_of_month)]
        if df_month.empty: continue
        row_month = aggregate_and_calculate_period(df_month, all_historical_data, start_of_month, end_of_month,
                                                   df_recharge_source)
        row_month['å¼€å§‹'] = start_of_month.strftime('%Y/%m/%d');
        row_month['ç»“æŸ'] = end_of_month.strftime('%Y/%m/%d')
        row_month['å‘¨æœŸ'] = f"{start_of_month.month}æœˆ";
        row_month['å§‹æ—¥-æœ«æœŸ'] = f"{start_of_month.month}æœˆ"
        report_list.append(row_month)

    for i in range(2):
        target_month_date = report_date - relativedelta(months=i)
        start_of_month = target_month_date.replace(day=1)
        _, days_in_month = calendar.monthrange(target_month_date.year, target_month_date.month)
        for week_num in range(1, 6):
            start_of_week = start_of_month + timedelta(days=(week_num - 1) * 7)
            end_of_week = start_of_week + timedelta(days=6)
            if start_of_week.month != target_month_date.month or start_of_week.day > days_in_month: break
            df_week = all_historical_data[
                (all_historical_data['æ—¥æœŸ'] >= start_of_week) & (all_historical_data['æ—¥æœŸ'] <= end_of_week)]
            if df_week.empty: continue
            row_week = aggregate_and_calculate_period(df_week, all_historical_data, start_of_week, end_of_week,
                                                      df_recharge_source)
            row_week['å¼€å§‹'] = start_of_week.strftime('%Y/%m/%d');
            row_week['ç»“æŸ'] = end_of_week.strftime('%Y/%m/%d')
            row_week['å‘¨æœŸ'] = f"ç¬¬{week_num}å‘¨";
            row_week['å§‹æ—¥-æœ«æœŸ'] = f"{start_of_week.strftime('%m/%d')}-{end_of_week.strftime('%m/%d')}"
            report_list.append(row_week)

    if not report_list: print("  [è­¦å‘Š] æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®ç”ŸæˆæœˆæŠ¥ã€‚"); return pd.DataFrame()
    df_final = pd.concat(report_list, ignore_index=True)

    this_month_data = df_final[df_final['å‘¨æœŸ'] == f"{report_date.month}æœˆ"].iloc[0:1]
    last_month_date = report_date - relativedelta(months=1)
    last_month_data = df_final[df_final['å‘¨æœŸ'] == f"{last_month_date.month}æœˆ"].iloc[0:1]

    if not this_month_data.empty and not last_month_data.empty:
        diff_row_data = this_month_data.select_dtypes(include=np.number).iloc[0] - \
                        last_month_data.select_dtypes(include=np.number).iloc[0]
        wow_row_data = diff_row_data / last_month_data.select_dtypes(include=np.number).iloc[0].replace(0, np.nan)
        diff_row = pd.DataFrame([{'å‘¨æœŸ': 'æ•°å·®', 'å§‹æ—¥-æœ«æœŸ': 'æœ¬æœˆ-ä¸Šæœˆ'}])
        wow_row = pd.DataFrame([{'å‘¨æœŸ': 'ç¯æ¯”', 'å§‹æ—¥-æœ«æœŸ': 'æœ¬æœˆ/ä¸Šæœˆ-1'}])
        for col in diff_row_data.index:
            if col in PRODUCT_REPORT_COLS: diff_row[col] = diff_row_data[col]
        for col in wow_row_data.index:
            if col in PRODUCT_REPORT_COLS: wow_row[col] = wow_row_data[col]
        df_final = pd.concat([df_final, diff_row, wow_row], ignore_index=True)

    for col in PRODUCT_MONTHLY_REPORT_COLS:
        if col not in df_final.columns: df_final[col] = ''

    return df_final[PRODUCT_MONTHLY_REPORT_COLS].fillna('')


def generate_summary_df(df_source, group_key, final_cols, time_period_str, all_historical_data=None,
                        df_recharge_dept=None, df_recharge_total=None):
    if df_source.empty: return pd.DataFrame(columns=final_cols)
    df_report = df_source.copy()

    if time_period_str == 'æ—¥æŠ¥':
        if group_key:
            df_summary = df_report.groupby(group_key, as_index=False).sum(numeric_only=True)
        else:
            df_summary = pd.DataFrame(df_report.sum(numeric_only=True)).T
            df_summary['äº§å“'] = PRODUCT_NAME

        df_summary = calculate_metrics(df_summary)
        report_date_val = df_report['æ—¥æœŸ'].iloc[0]
        group_cols = group_key if group_key else []

        for days in [7, 15, 30]:
            start_date = report_date_val - timedelta(days=days - 1)
            window_df = all_historical_data[
                (all_historical_data['æ—¥æœŸ'] >= start_date) & (all_historical_data['æ—¥æœŸ'] <= report_date_val)]
            if not window_df.empty:
                if not group_cols:
                    total_recharge = window_df['å……å€¼é‡‘é¢(U)'].sum()
                    total_new_users = window_df['æ–°å¢ç”¨æˆ·æ•°'].sum()
                    df_summary[f'LTV-{days}å¤©'] = total_recharge / total_new_users if total_new_users else 0
                else:
                    ltv_agg = window_df.groupby(group_cols)[['å……å€¼é‡‘é¢(U)', 'æ–°å¢ç”¨æˆ·æ•°']].sum().reset_index()
                    ltv_agg[f'LTV-{days}å¤©'] = ltv_agg['å……å€¼é‡‘é¢(U)'] / ltv_agg['æ–°å¢ç”¨æˆ·æ•°'].replace(0, np.nan)
                    if not ltv_agg.empty: df_summary = pd.merge(df_summary, ltv_agg[group_cols + [f'LTV-{days}å¤©']],
                                                                on=group_cols, how='left')
            else:
                df_summary[f'LTV-{days}å¤©'] = 0

        # [å…³é”®ä¿®å¤] ä½¿ç”¨ç‰ˆæœ¬ä¸€ä¸­ç»è¿‡éªŒè¯çš„å¤å……ç‡åˆå¹¶é€»è¾‘
        if not group_key and df_recharge_total is not None and not df_recharge_total.empty:
            for rate_col, value in df_recharge_total.items():
                df_summary[rate_col] = value
        elif 'éƒ¨é—¨' in group_key and df_recharge_dept is not None and not df_recharge_dept.empty:
            # æ¸ é“æŠ¥è¡¨ä¹Ÿåº”è¯¥ç»§æ‰¿å…¶æ‰€å±éƒ¨é—¨çš„å¤å……ç‡
            df_summary = pd.merge(df_summary, df_recharge_dept, on='éƒ¨é—¨', how='left')

        df_summary['æ—¥æœŸ'] = report_date_val
    else:
        grouping_keys = group_key + ['æ—¥æœŸ'] if group_key else ['æ—¥æœŸ']
        if 'äº§å“' in group_key: grouping_keys = ['æ—¥æœŸ']
        df_summary = df_report.groupby(grouping_keys, as_index=False).sum(numeric_only=True)
        if 'äº§å“' in group_key: df_summary['äº§å“'] = PRODUCT_NAME
        df_summary = calculate_metrics(df_summary)

    for col in final_cols:
        if col not in df_summary.columns:
            df_summary[col] = 0

    if time_period_str != 'æ—¥æŠ¥':
        numeric_cols = df_summary.select_dtypes(include=np.number).columns.tolist()
        total_row = pd.DataFrame(df_summary[numeric_cols].sum()).T
        total_row = calculate_metrics(total_row)
        total_row['æ—¥æœŸ'] = "æ€»è®¡"
        if group_key: total_row[group_key[0]] = 'æ€»è®¡'

        df_summary = pd.concat([df_summary, total_row], ignore_index=True)

    return df_summary[final_cols].fillna(0)


# ==================== Main ä¸»å‡½æ•° ====================
def main():
    print("--- æŠ¥è¡¨ç”Ÿæˆå™¨å¼€å§‹è¿è¡Œ ---")
    try:
        # å¦‚æœåœ¨æ‰“åŒ…åçš„ .exe ç¯å¢ƒä¸­è¿è¡Œ, ä½¿ç”¨ sys._MEIPASS
        script_dir = sys._MEIPASS
    except AttributeError:
        # å¦åˆ™, åœ¨æ­£å¸¸çš„ .py ç¯å¢ƒä¸­è¿è¡Œ
        script_dir = os.path.dirname(os.path.abspath(__file__))
    print(f"è„šæœ¬è¿è¡Œç›®å½•: {script_dir}\n")

    # --- 1. è¯»å–æ‰€æœ‰æºæ–‡ä»¶ ---
    df_channel = find_and_read_file(script_dir, 'download_æ¸ é“æŠ¥è¡¨_*.csv', is_critical=True,
                                    file_description="æ¸ é“æŠ¥è¡¨")
    df_ops = find_and_read_file(script_dir, 'download_è¿è¥æŠ¥è¡¨_*.csv', file_description="è¿è¥æŠ¥è¡¨")
    df_mapping = find_and_read_file(script_dir, 'æ€»ä»£åç§°éƒ¨é—¨è§„å¾‹è¡¨.csv', is_critical=True,
                                    file_description="éƒ¨é—¨æ˜ å°„è¡¨")
    df_recharge_source = find_and_read_file(script_dir, 'download_é¦–å……ç”¨æˆ·åˆ†æ_*.csv',
                                            file_description="é¦–å……ç”¨æˆ·åˆ†ææŠ¥è¡¨")
    df_spend = get_spend_data_from_google_sheet(SPEND_SHEET_URL)

    for df in [df_channel, df_ops, df_spend, df_recharge_source]:
        if df is not None and 'æ—¥æœŸ' in df.columns:
            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce').dt.date

    # --- 2. åˆå¹¶ä¸é¢„å¤„ç†æ•°æ® ---
    print("\n--- æ­£åœ¨åˆå¹¶æ‰€æœ‰å†å²æ•°æ® ---")
    df_merged = df_channel.copy()
    if df_ops is not None and 'è€ç©å®¶æ—¥æ´»' in df_ops.columns:
        df_merged = pd.merge(df_merged, df_ops[['æ—¥æœŸ', 'è€ç©å®¶æ—¥æ´»']].drop_duplicates(subset=['æ—¥æœŸ']), on='æ—¥æœŸ',
                             how='left', suffixes=('_old', ''))
        if 'è€ç©å®¶æ—¥æ´»_old' in df_merged.columns: df_merged = df_merged.drop(columns=['è€ç©å®¶æ—¥æ´»_old'])

    if df_spend is not None:
        df_merged = pd.merge(df_merged, df_spend.drop_duplicates(subset=['æ—¥æœŸ']), on='æ—¥æœŸ', how='left')
    df_merged.fillna(0, inplace=True)
    df_merged['äº§å“'] = PRODUCT_NAME
    cols_to_numerify = ['æ–°å¢ç”¨æˆ·æ•°', 'å……å€¼äººæ•°', 'å……å€¼é‡‘é¢', 'æç°é‡‘é¢', 'é¦–å­˜äººæ•°', 'é¦–å­˜å……å€¼é‡‘é¢', 'æ–°å¢ä»˜è´¹äººæ•°',
                        'æ–°å¢å……å€¼é‡‘é¢', 'è€ç”¨æˆ·å……å€¼äººæ•°', 'è€ç”¨æˆ·å……å€¼é‡‘é¢', 'è€ç”¨æˆ·æç°é‡‘é¢', 'è€ç©å®¶æ—¥æ´»']
    for col in cols_to_numerify:
        if col in df_merged.columns: df_merged[col] = pd.to_numeric(df_merged[col], errors='coerce').fillna(0)
    df_merged['éƒ¨é—¨'] = df_merged['æ¸ é“æ¥æº'].apply(lambda x: next(
        (dept for keyword, dept in zip(df_mapping.iloc[:, 1], df_mapping.iloc[:, 0]) if keyword in str(x)), 'unknown'))
    all_historical_data = calculate_metrics(df_merged)
    all_historical_data.dropna(subset=['æ—¥æœŸ'], inplace=True)
    all_historical_data['æ—¥æœŸ'] = pd.to_datetime(all_historical_data['æ—¥æœŸ'], errors='coerce').dt.date

    report_date = pd.to_datetime(OVERRIDE_DATE).date() if OVERRIDE_DATE and str(OVERRIDE_DATE).strip() != "" else \
    all_historical_data['æ—¥æœŸ'].max()
    report_date_str = report_date.strftime('%Y%m%d')
    report_date_str_display = report_date.strftime('%Y-%m-%d')
    print(f"\n[æ ¸å¿ƒ] å°†ä¸ºæ—¥æœŸ: {report_date_str_display} ç”ŸæˆæŠ¥è¡¨")

    df_recharge_dept, df_recharge_total = pd.DataFrame(), pd.Series(dtype=float)
    if df_recharge_source is not None:
        df_recharge_dept, df_recharge_total = read_and_process_recharge_data(df_recharge_source, df_mapping,
                                                                             report_date)

    # --- 3. ç”Ÿæˆæ‰€æœ‰æŠ¥è¡¨çš„DataFrame ---
    df_daily = all_historical_data[all_historical_data['æ—¥æœŸ'] == report_date].copy()
    df_weekly = all_historical_data[
        (all_historical_data['æ—¥æœŸ'] >= report_date - timedelta(days=report_date.weekday())) & (
                    all_historical_data['æ—¥æœŸ'] <= report_date)].copy()
    df_monthly = all_historical_data[(all_historical_data['æ—¥æœŸ'] >= report_date.replace(day=1)) & (
                all_historical_data['æ—¥æœŸ'] <= report_date)].copy()

    daily_reports = {
        "äº§å“æ—¥æŠ¥": generate_summary_df(df_daily, [], PRODUCT_COLS, 'æ—¥æŠ¥', all_historical_data, df_recharge_dept=None,
                                        df_recharge_total=df_recharge_total),
        "éƒ¨é—¨æ—¥æŠ¥": generate_summary_df(df_daily, ['éƒ¨é—¨'], DEPT_COLS, 'æ—¥æŠ¥', all_historical_data,
                                        df_recharge_dept=df_recharge_dept, df_recharge_total=None),
        "æ¸ é“æ—¥æŠ¥": generate_summary_df(df_daily, ['éƒ¨é—¨', 'æ¸ é“æ¥æº'], CHANNEL_COLS, 'æ—¥æŠ¥', all_historical_data,
                                        df_recharge_dept=df_recharge_dept, df_recharge_total=None)
    }
    weekly_reports = {
        "äº§å“å‘¨æŠ¥æ€»æ±‡": generate_product_weekly_report(all_historical_data, report_date, df_recharge_source),
        "éƒ¨é—¨å‘¨æŠ¥æ€»æ±‡": generate_summary_df(df_weekly, ['éƒ¨é—¨'], DEPT_COLS, 'å‘¨æŠ¥æ€»æ±‡')
    }
    monthly_reports = {
        "äº§å“æœˆæŠ¥æ€»æ±‡": generate_product_monthly_report(all_historical_data, report_date, df_recharge_source),
        "éƒ¨é—¨æœˆæŠ¥æ€»æ±‡": generate_summary_df(df_monthly, ['éƒ¨é—¨'], DEPT_COLS, 'æœˆæŠ¥æ€»æ±‡')
    }

    # --- 4. è¾“å‡ºåˆ°Excelå’ŒHTML ---
    output_filename_base = f"{report_date_str}_{PRODUCT_NAME}_ç»¼åˆæŠ¥è¡¨"
    excel_filename = f"{output_filename_base}.xlsx"
    html_filename = f"{output_filename_base}.html"

    with pd.ExcelWriter(excel_filename, engine='xlsxwriter') as writer:
        write_tables_to_sheet(writer, 'æ—¥æŠ¥', daily_reports, f"{PRODUCT_NAME} - æ—¥æŠ¥ - {report_date_str_display}")
        write_tables_to_sheet(writer, 'å‘¨æŠ¥', weekly_reports, f"{PRODUCT_NAME} - å‘¨æŠ¥ - {report_date_str_display}")
        write_tables_to_sheet(writer, 'æœˆæŠ¥', monthly_reports, f"{PRODUCT_NAME} - æœˆæŠ¥ - {report_date_str_display}")

    export_reports_to_html(html_filename, daily_reports, weekly_reports, monthly_reports, report_date_str_display)

    print("\n" + "=" * 60)
    print(f"ğŸ‰ æŠ¥è¡¨ç”ŸæˆæˆåŠŸï¼å·²ä¸ºæ‚¨åˆ›å»ºä¸¤ä¸ªæ–‡ä»¶:")
    print(f"  1. [ExcelæŠ¥è¡¨] {excel_filename}")
    print(f"  2. [ç½‘é¡µ/PDFæºæ–‡ä»¶] {html_filename}")
    print("\n  >> å¦‚ä½•ç”ŸæˆPDF: <<")
    print(f"  è¯·ç”¨Chromeæˆ–Edgeæµè§ˆå™¨æ‰“å¼€ {html_filename}ï¼Œ")
    print("  ç„¶åç‚¹å‡» 'æ‰“å°(Print)' -> 'ç›®æ ‡æ‰“å°æœº(Destination)' -> 'å¦å­˜ä¸ºPDF(Save as PDF)'ã€‚")
    print("=" * 60)


if __name__ == '__main__':
    main()
