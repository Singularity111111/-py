import pandas as pd
import glob
import os
import numpy as np
from datetime import datetime, timedelta, date
import io
import warnings
# å¼•å…¥ SettingWithCopyWarningï¼Œè§£å†³ AttributeError
from pandas.errors import SettingWithCopyWarning

# å¿½ç•¥ Pandas é“¾å¼èµ‹å€¼çš„è­¦å‘Šï¼Œä»¥ä¿æŒä»£ç ç®€æ´
warnings.filterwarnings("ignore", category=SettingWithCopyWarning)

# ==================== ç»ˆæé…ç½®åŒº ====================
EXCHANGE_RATE = 280  # æ±‡ç‡é…ç½®ï¼Œä¾‹å¦‚ 1 USD = 280 PKR
SEARCH_PATH = "."    # æœç´¢æœ¬åœ°æºæ–‡ä»¶çš„è·¯å¾„
OUTPUT_FILENAME = 'æœ€ç»ˆç”Ÿæˆä¸‰ç»´åº¦æŠ¥è¡¨.xlsx'
# å®šä¹‰å°è¯•è¯»å–æœ¬åœ°CSVæ–‡ä»¶çš„ç¼–ç åˆ—è¡¨ï¼šå¢åŠ æ›´å¤šå¯èƒ½æ€§
CSV_ENCODINGS = ['utf-8', 'gbk', 'latin1', 'ISO-8859-1', 'cp1252']

# === Google Sheet æ¶ˆè€—æ•°æ®é“¾æ¥ ===
# æˆ‘ä»¬å°†æŠŠä½ çš„é“¾æ¥è½¬æ¢æˆä¸€ä¸ªå¯ä»¥ç›´æ¥ä¸‹è½½CSVçš„é“¾æ¥
SPEND_SHEET_URL = "https://docs.google.com/spreadsheets/d/1v_GQLJ28byHFUqfcvdo2OtAbLQaMOCBL9x7Q-MqkjmI/export?format=csv"

# ==================== æœ€ç»ˆè¾“å‡ºå­—æ®µå®šä¹‰ ====================
# A. äº§å“æ€»æ±‡è¡¨å­—æ®µ (åŒ…å« 'äº§å“' ç»´åº¦)
PRODUCT_COLS = [
    'æ—¥æœŸ', 'äº§å“', 'æ€»æ¶ˆè€—(U)', 'æ³¨å†Œæˆæœ¬', 'é¦–å……æˆæœ¬', 'æ–°å¢ç”¨æˆ·æ•°', 'å……å€¼äººæ•°', 'å……å€¼é‡‘é¢(U)', 'æç°é‡‘é¢(U)', 
    'å……å‡æ(U)', 'ç›ˆä½™ç‡(%)', 'é¦–å­˜äººæ•°', 'é¦–å­˜å……å€¼é‡‘é¢(U)', 'é¦–å­˜ä»˜è´¹ç‡(%)', 'é¦–å­˜ç›ˆä½™ç‡(%)', 
    'é¦–å­˜ARPPU', 'æ–°å¢ä»˜è´¹äººæ•°', 'æ–°å¢å……å€¼é‡‘é¢(U)', 'æ–°å¢ä»˜è´¹ç‡(%)', 'è€ç”¨æˆ·å……å€¼äººæ•°', 
    'è€ç”¨æˆ·å……å€¼é‡‘é¢(U)', 'è€ç”¨æˆ·ä»˜è´¹ç‡(%)', 'è€ç”¨æˆ·ARPPU', 'è€ç”¨æˆ·ç›ˆä½™ç‡(%)', 'ARPPU', 
    'æ¬¡æ—¥å¤å……ç‡(%)', '3æ—¥å¤å……ç‡(%)', '7æ—¥å¤å……ç‡(%)', '15æ—¥å¤å……ç‡(%)', '30æ—¥å¤å……ç‡(%)', 
    'LTV-7å¤©', 'LTV-15å¤©', 'LTV-30å¤©', 'è£‚å˜ç‡', 'å†å²æ¶ˆè€—(U)', 'å†å²å……æå·®(U)', 'è¾…åŠ©åˆ—'
]

# B. éƒ¨é—¨æ€»æ±‡è¡¨å­—æ®µ (åŒ…å« 'éƒ¨é—¨' ç»´åº¦)
DEPT_COLS = [
    'æ—¥æœŸ', 'éƒ¨é—¨', 'æ€»æ¶ˆè€—(U)', 'æ³¨å†Œæˆæœ¬', 'é¦–å……æˆæœ¬', 'æ–°å¢ç”¨æˆ·æ•°', 'å……å€¼äººæ•°', 'å……å€¼é‡‘é¢(U)', 'æç°é‡‘é¢(U)', 
    'å……å‡æ(U)', 'ç›ˆä½™ç‡(%)', 'é¦–å­˜äººæ•°', 'é¦–å­˜å……å€¼é‡‘é¢(U)', 'é¦–å­˜ä»˜è´¹ç‡(%)', 'é¦–å­˜ç›ˆä½™ç‡(%)', 
    'é¦–å­˜ARPPU', 'æ–°å¢ä»˜è´¹äººæ•°', 'æ–°å¢å……å€¼é‡‘é¢(U)', 'æ–°å¢ä»˜è´¹ç‡(%)', 'è€ç”¨æˆ·å……å€¼äººæ•°', 
    'è€ç”¨æˆ·å……å€¼é‡‘é¢(U)', 'è€ç”¨æˆ·ä»˜è´¹ç‡(%)', 'è€ç”¨æˆ·ARPPU', 'è€ç”¨æˆ·ç›ˆä½™ç‡(%)', 'ARPPU', 
    'æ¬¡æ—¥å¤å……ç‡(%)', '3æ—¥å¤å……ç‡(%)', '7æ—¥å¤å……ç‡(%)', '15æ—¥å¤å……ç‡(%)', '30æ—¥å¤å……ç‡(%)', 
    'LTV-7å¤©', 'LTV-15å¤©', 'LTV-30å¤©', 'è€ç”¨æˆ·å……å‡æ(U)', 'å†å²æ¶ˆè€—(U)', 'å†å²å……æå·®(U)', 'è€ç©å®¶æ—¥æ´»'
]

# C. æ¸ é“æ€»æ±‡è¡¨å­—æ®µ (åŒ…å« 'æ¸ é“æ¥æº' å’Œ 'éƒ¨é—¨' ç»´åº¦)
CHANNEL_COLS = [
    'æ—¥æœŸ', 'éƒ¨é—¨', 'æ¸ é“æ¥æº', 'æ€»æ¶ˆè€—(U)', 'æ³¨å†Œæˆæœ¬', 'é¦–å……æˆæœ¬', 'æ–°å¢ç”¨æˆ·æ•°', 'å……å€¼äººæ•°', 'å……å€¼é‡‘é¢(U)', 
    'æç°é‡‘é¢(U)', 'å……å‡æ(U)', 'ç›ˆä½™ç‡(%)', 'é¦–å­˜äººæ•°', 'é¦–å­˜å……å€¼é‡‘é¢(U)', 'é¦–å­˜ä»˜è´¹ç‡(%)', 
    'é¦–å­˜ç›ˆä½™ç‡(%)', 'é¦–å­˜ARPPU', 'æ–°å¢ä»˜è´¹äººæ•°', 'æ–°å¢å……å€¼é‡‘é¢(U)', 'æ–°å¢ä»˜è´¹ç‡(%)', 'è€ç”¨æˆ·å……å€¼äººæ•°', 
    'è€ç”¨æˆ·å……å€¼é‡‘é¢(U)', 'è€ç”¨æˆ·ä»˜è´¹ç‡(%)', 'è€ç”¨æˆ·ARPPU', 'è€ç”¨æˆ·ç›ˆä½™ç‡(%)', 'ARPPU', 
    'æ¬¡æ—¥å¤å……ç‡(%)', '3æ—¥å¤å……ç‡(%)', '7æ—¥å¤å……ç‡(%)', '15æ—¥å¤å……ç‡(%)', '30æ—¥å¤å……ç‡(%)', 
    'LTV-7å¤©', 'LTV-15å¤©', 'LTV-30å¤©', 'è€ç”¨æˆ·å……å‡æ(U)', 'å†å²æ¶ˆè€—(U)', 'å†å²å……æå·®(U)', 'è€ç©å®¶æ—¥æ´»'
]

# ==================== è¾…åŠ©å‡½æ•° ====================

def read_source_file(file_pattern):
    """è¯»å–æŒ‡å®šæ¨¡å¼ä¸‹çš„æœ€æ–°æ–‡ä»¶ï¼Œå¹¶å¤„ç† CSV ç¼–ç åŠ CSV/Excel è¯†åˆ«é—®é¢˜"""
    files = glob.glob(os.path.join(SEARCH_PATH, file_pattern))
    if not files: 
        print(f"  [è­¦å‘Š] æœªæ‰¾åˆ°æ–‡ä»¶: {file_pattern}"); 
        return None
    latest_file = max(files, key=os.path.getctime)
    print(f"  æ­£åœ¨è¯»å–: {os.path.basename(latest_file)}")
    
    # ä¼˜å…ˆå°è¯•è¯»å–ä¸º CSV (å¤„ç†ç¼–ç é—®é¢˜)
    if file_pattern.endswith('.csv'):
        df = None
        for encoding in CSV_ENCODINGS:
            try:
                # å°è¯•ç”¨å½“å‰ç¼–ç è¯»å–
                df = pd.read_csv(latest_file, encoding=encoding)
                print(f"  [æˆåŠŸ] ä½¿ç”¨ '{encoding}' ç¼–ç è¯»å– CSV æ–‡ä»¶æˆåŠŸ.")
                return df
            except Exception:
                continue
        
        # å¦‚æœæ‰€æœ‰ CSV å°è¯•éƒ½å¤±è´¥äº†ï¼Œå¯èƒ½æ˜¯ Excel æ–‡ä»¶è¢«é”™è¯¯å‘½åä¸º CSV
        try:
            df = pd.read_excel(latest_file)
            print("  [æˆåŠŸ] CSV ç¼–ç å¤±è´¥ï¼Œä½†ä»¥ Excel æ ¼å¼è¯»å–æˆåŠŸ.")
            return df
        except Exception as e_excel:
            print(f"  [é”™è¯¯] æ–‡ä»¶è¯»å–å¤±è´¥: æ‰€æœ‰å°è¯•çš„ç¼–ç  ({', '.join(CSV_ENCODINGS)}) éƒ½æœªèƒ½æˆåŠŸè§£ææ–‡ä»¶ï¼Œä¸”æ— æ³•ä½œä¸º Excel è¯»å–: {e_excel}")
            return None
    
    # å¯¹äºæ˜ç¡®çš„ Excel æ–‡ä»¶ (.xlsx, .xls)
    else:
        try:
            return pd.read_excel(latest_file)
        except Exception as e: 
            print(f"  [é”™è¯¯] è¯»å–æ–‡ä»¶å¤±è´¥: {e}"); 
            return None

def get_spend_data_from_google_sheet(url):
    """ä»Google Sheeté“¾æ¥è‡ªåŠ¨è·å–æ¶ˆè€—æ•°æ®ï¼Œå¹¶å¤„ç†æ•°å€¼è½¬æ¢é”™è¯¯"""
    print("æ­£åœ¨ä»Google Sheeté“¾æ¥è‡ªåŠ¨è¯»å–'æ¶ˆè€—'æ•°æ®...")
    try:
        # Pandaså¯ä»¥ç›´æ¥ä»URLè¯»å–CSVæ•°æ®
        df_spend_raw = pd.read_csv(url)
        print("  [æˆåŠŸ] å·²ä»é“¾æ¥è·å–æ•°æ®ã€‚")
        
        # æ•°æ®å¤„ç†
        # ç»Ÿä¸€æ—¥æœŸæ ¼å¼ä¸º datetime.date
        df_spend_raw['æ—¥æœŸ'] = pd.to_datetime(df_spend_raw['æ—¥æœŸ'], format='%Y%m%d').dt.date
        
        # ç­›é€‰å‡ºæ‰€æœ‰æ•°å€¼åˆ—ç”¨äºæ±‚å’Œ (æ’é™¤'æ—¥æœŸ'å’Œ'å’Œ'è¿™ä¸¤åˆ—)
        spend_cols = [col for col in df_spend_raw.columns if col not in ['æ—¥æœŸ', 'å’Œ', 'å¤‡æ³¨']]
        
        # === ä¿®å¤ï¼šå¼ºåˆ¶è½¬æ¢æ•°å€¼ç±»å‹ï¼Œè§£å†³ can only concatenate str é”™è¯¯ ===
        # errors='coerce' ä¼šå°†æ— æ³•è½¬æ¢çš„å€¼ï¼ˆä¾‹å¦‚è¡¨æ ¼ä¸­çš„ç©ºå€¼ã€æ–‡æœ¬ï¼‰è®¾ä¸º NaN
        for col in spend_cols:
            df_spend_raw[col] = pd.to_numeric(df_spend_raw[col], errors='coerce')
        
        # è®¡ç®—æ€»æ¶ˆè€— (NaN ä¼šè¢«è‡ªåŠ¨å¿½ç•¥)
        df_spend_raw['æ€»æ¶ˆè€—(U)'] = df_spend_raw[spend_cols].sum(axis=1)
        
        # å†å²ç´¯è®¡æ•°æ®ï¼šä½¿ç”¨ç´¯åŠ å’Œè®¡ç®—å†å²æ¶ˆè€—
        df_spend_raw['å†å²æ¶ˆè€—(U)'] = df_spend_raw['æ€»æ¶ˆè€—(U)'].cumsum()
        
        # è¿”å›æ ¸å¿ƒæ¶ˆè€—æ•°æ®
        return df_spend_raw[['æ—¥æœŸ', 'æ€»æ¶ˆè€—(U)', 'å†å²æ¶ˆè€—(U)']]
    except Exception as e:
        print(f"  [é”™è¯¯] è‡ªåŠ¨è¯»å–Google Sheetå¤±è´¥: {e}")
        print("  è¯·æ£€æŸ¥é“¾æ¥æ˜¯å¦æœ‰æ•ˆï¼Œæˆ–è€…ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸ã€‚")
        return pd.DataFrame(columns=['æ—¥æœŸ', 'æ€»æ¶ˆè€—(U)', 'å†å²æ¶ˆè€—(U)'])

def calculate_metrics(df):
    """è®¡ç®—æ‰€æœ‰è¡ç”ŸæŒ‡æ ‡ï¼Œå¹¶è¿›è¡Œå¸ç§è½¬æ¢"""
    df = df.copy()
    
    # 1. è´§å¸å•ä½è½¬æ¢ (PKR -> U)
    currency_cols_pkr = [
        'å……å€¼é‡‘é¢', 'æç°é‡‘é¢', 'é¦–å­˜å……å€¼é‡‘é¢', 'è€ç”¨æˆ·å……å€¼é‡‘é¢', 
        # å‡è®¾ä»¥ä¸‹å­—æ®µä¹Ÿå¯èƒ½åœ¨æºæ•°æ®ä¸­ï¼Œä¸”éœ€è¦è½¬æ¢
        'æŠ•æ³¨é‡‘é¢', 'ä½£é‡‘', 'è€ç”¨æˆ·æç°é‡‘é¢', 'æ–°å¢å……å€¼é‡‘é¢' 
    ]
    for col in currency_cols_pkr:
        if col in df.columns and f'{col}(U)' not in df.columns:
            # ä»…å¯¹æœªè½¬æ¢çš„åˆ—è¿›è¡Œè½¬æ¢
            df[f'{col}(U)'] = df[col].astype(float) / EXCHANGE_RATE
        elif col in df.columns and f'{col}(U)' in df.columns:
            # å¦‚æœåŸå§‹åˆ—å’Œ(U)åˆ—éƒ½åœ¨ï¼Œç¡®ä¿(U)åˆ—æ˜¯floatç±»å‹
            df[f'{col}(U)'] = df[f'{col}(U)'].astype(float)
        
    # é‡å‘½å LTV/å¤å……ç‡ ç›¸å…³çš„åˆ—ï¼Œä»¥ä¾¿åç»­é€‰æ‹©
    df.rename(columns={
        'æ¬¡æ—¥ç•™å­˜(%)': 'æ¬¡æ—¥å¤å……ç‡(%)', 
        '3æ—¥ç•™å­˜(%)': '3æ—¥å¤å……ç‡(%)', 
        '7æ—¥ç•™å­˜(%)': '7æ—¥å¤å……ç‡(%)',
        '15æ—¥ç•™å­˜(%)': '15æ—¥å¤å……ç‡(%)',
        '30æ—¥ç•™å­˜(%)': '30æ—¥å¤å……ç‡(%)'
    }, inplace=True)

    # 2. æ ¸å¿ƒè®¡ç®— (é¿å…é™¤é›¶/æ— é™å¤§é”™è¯¯)
    with np.errstate(divide='ignore', invalid='ignore'):
        
        # å……å‡æ
        df['å……å‡æ(U)'] = df.get('å……å€¼é‡‘é¢(U)', 0) - df.get('æç°é‡‘é¢(U)', 0)
        
        # å†å²å……æå·®(U) - éœ€è¦åœ¨åˆ†ç»„æ±‚å’Œåæ‰èƒ½è®¡ç®—å‡†ç¡®ï¼Œè¿™é‡Œå…ˆè®¾ä¸ºå ä½ç¬¦
        # åœ¨ main å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç´¯åŠ å’Œè®¡ç®—è¿™ä¸ªå­—æ®µã€‚
        df['å†å²å……æå·®(U)'] = df.get('å†å²å……æå·®(U)', 0) 
        
        # è€ç”¨æˆ·å……å‡æ(U) - å‡è®¾æºæ•°æ®æ²¡æœ‰è€ç”¨æˆ·æç°é‡‘é¢ï¼Œä½¿ç”¨è€ç”¨æˆ·å……å€¼é‡‘é¢ä½œä¸ºå……å‡æçš„ä»£ç†
        # æˆ–è€…å‡è®¾è€ç”¨æˆ·æç°é‡‘é¢å¯ä»¥è¢«ä¼°ç®—
        df['è€ç”¨æˆ·å……å‡æ(U)'] = df.get('è€ç”¨æˆ·å……å€¼é‡‘é¢(U)', 0) - df.get('è€ç”¨æˆ·æç°é‡‘é¢(U)', 0)
        
        # æˆæœ¬ / ç›ˆä½™ç‡
        df['æ€»æ¶ˆè€—(U)'] = df.get('æ€»æ¶ˆè€—(U)', 0) # ç¡®ä¿å­˜åœ¨
        df['æ³¨å†Œæˆæœ¬'] = np.divide(df['æ€»æ¶ˆè€—(U)'], df.get('æ–°å¢ç”¨æˆ·æ•°', 0))
        df['é¦–å……æˆæœ¬'] = np.divide(df['æ€»æ¶ˆè€—(U)'], df.get('é¦–å­˜äººæ•°', 0))
        df['ç›ˆä½™ç‡(%)'] = np.divide(df['å……å‡æ(U)'], df.get('å……å€¼é‡‘é¢(U)', 0))
        
        # ä»˜è´¹ç‡ / ARPPU / ARPU
        # é¦–å­˜ä»˜è´¹ç‡(%) - ç¡®ä¿å­˜åœ¨
        df['é¦–å­˜ä»˜è´¹ç‡(%)'] = df.get('é¦–å­˜ä»˜è´¹ç‡(%)', 0)
        # æ–°å¢ä»˜è´¹ç‡(%)
        df['æ–°å¢ä»˜è´¹ç‡(%)'] = np.divide(df.get('æ–°å¢ä»˜è´¹äººæ•°', 0), df.get('æ–°å¢ç”¨æˆ·æ•°', 0))
        # è€ç”¨æˆ·ä»˜è´¹ç‡(%)
        df['è€ç”¨æˆ·ä»˜è´¹ç‡(%)'] = np.divide(df.get('è€ç”¨æˆ·å……å€¼äººæ•°', 0), df.get('è€ç©å®¶æ—¥æ´»', 0))
        # æ€»ä»˜è´¹ç‡(%)
        df['ä»˜è´¹ç‡(%)'] = np.divide(df.get('å……å€¼äººæ•°', 0), df.get('æ—¥æ´»è·ƒç©å®¶æ•°', 0))
        
        # ARPPU (Average Revenue Per Paying User)
        df['é¦–å­˜ARPPU'] = np.divide(df.get('é¦–å­˜å……å€¼é‡‘é¢(U)', 0), df.get('é¦–å­˜äººæ•°', 0))
        df['æ–°å¢ARPPU'] = np.divide(df.get('æ–°å¢å……å€¼é‡‘é¢(U)', 0), df.get('æ–°å¢ä»˜è´¹äººæ•°', 0))
        df['è€ç”¨æˆ·ARPPU'] = np.divide(df.get('è€ç”¨æˆ·å……å€¼é‡‘é¢(U)', 0), df.get('è€ç”¨æˆ·å……å€¼äººæ•°', 0))
        df['ARPPU'] = np.divide(df.get('å……å€¼é‡‘é¢(U)', 0), df.get('å……å€¼äººæ•°', 0)) # Total ARPPU
        
    # 3. æœ€ç»ˆæ¸…ç†
    df.replace([np.inf, -np.inf], 0, inplace=True); df.fillna(0, inplace=True)
    return df

def generate_summary_sheet(df_source, group_key, final_cols, time_period_str, sheet_name, writer):
    """ç”Ÿæˆæ¯æ—¥ã€æ¯å‘¨æ€»æ±‡æˆ–æ¯æœˆæ€»æ±‡çš„æ ‡å‡†æŠ¥è¡¨"""
    
    df_report = df_source.copy()
    
    # 1. å¯¹åˆ†ç»„å’Œæ—¥æœŸè¿›è¡Œæ±‚å’Œ (ä»…å¯¹æ•°å€¼åˆ—)
    # æ’é™¤åˆ†ç»„å­—æ®µå’Œå†å²ç´¯è®¡å­—æ®µï¼ˆå†å²å­—æ®µä¸åº”è¯¥åœ¨æ±‚å’Œä¸­è¢«è®¡ç®—ï¼‰
    sum_cols = [col for col in df_report.columns if col not in group_key and col != 'æ—¥æœŸ' and 'å†å²' not in col and not df_report[col].dtype == object]
    
    # å‘¨æŠ¥/æœˆæŠ¥éœ€è¦å¯¹æ•°æ®è¿›è¡Œæ±‚å’Œ
    if time_period_str != 'æ—¥æŠ¥':
        df_report = df_report.groupby(group_key)[sum_cols].sum().reset_index()
    
    # 2. é‡æ–°è®¡ç®—è¡ç”ŸæŒ‡æ ‡
    df_report = calculate_metrics(df_report)
    
    # 3. ç¡®ä¿æœ€ç»ˆå­—æ®µéƒ½å­˜åœ¨ï¼Œå¹¶é€‰æ‹©å­—æ®µ
    for col in final_cols:
        if col not in df_report.columns:
            df_report[col] = 0

    # 4. è¾“å‡ºåˆ° Excel
    df_report = df_report[final_cols]
    
    # å¦‚æœæ˜¯å‘¨æŠ¥æˆ–æœˆæŠ¥æ€»æ±‡ï¼Œæ·»åŠ æ€»è®¡è¡Œ
    if time_period_str != 'æ—¥æŠ¥':
        total_row = df_report.sum(numeric_only=True).to_frame().T
        # ç¡®ä¿æ€»è®¡è¡Œä¸ä¸»DFå…·æœ‰ç›¸åŒçš„åˆ—ç»“æ„ï¼Œä»¥ä¾¿åç»­åˆå¹¶
        total_row = total_row.reindex(columns=df_report.columns, fill_value=0)
        total_row[group_key[0]] = 'æ€»è®¡' # å‡è®¾ç¬¬ä¸€ä¸ªåˆ†ç»„é”®è¶³ä»¥æ ‡è¯†æ€»è®¡
        
        df_report = pd.concat([df_report, total_row], ignore_index=True)
        
        # === ä¿®å¤ï¼šä½¿ç”¨ loc å’Œ isin æ¥å®‰å…¨åœ°é‡æ–°è®¡ç®—æ€»è®¡è¡Œçš„ç™¾åˆ†æ¯”/æˆæœ¬æŒ‡æ ‡ ===
        # æ‰¾åˆ°æ€»è®¡è¡Œçš„ç´¢å¼•ä½ç½®
        total_idx = df_report[df_report[group_key[0]] == 'æ€»è®¡'].index
        
        # éš”ç¦»æ€»è®¡è¡Œè¿›è¡Œè®¡ç®—
        df_total_calc = df_report.loc[total_idx].copy()
        df_total_calc = calculate_metrics(df_total_calc)
        
        # æå–éœ€è¦æ›´æ–°çš„æŒ‡æ ‡åˆ—
        metrics_to_update = ['æ³¨å†Œæˆæœ¬', 'é¦–å……æˆæœ¬', 'ç›ˆä½™ç‡(%)', 'æ–°å¢ä»˜è´¹ç‡(%)', 'è€ç”¨æˆ·ä»˜è´¹ç‡(%)', 'ä»˜è´¹ç‡(%)', 'é¦–å­˜ARPPU', 'æ–°å¢ARPPU', 'è€ç”¨æˆ·ARPPU', 'ARPPU']
        
        # å®‰å…¨åœ°å°†è®¡ç®—ç»“æœå†™å›åˆ°åŸå§‹DataFrameçš„æ€»è®¡è¡Œ
        df_report.loc[total_idx, metrics_to_update] = df_total_calc[metrics_to_update].values
    
    df_report.to_excel(writer, sheet_name=sheet_name, index=False)
    print(f"{sheet_name} å·²ç”Ÿæˆ...")

def generate_comparison_sheets(df_source, group_key, final_cols, writer, period_type='å‘¨'):
    """ç”Ÿæˆäº§å“ç»´åº¦ç‰¹æ®Šçš„ 'æ€»æ±‡' å’Œ 'ç¯æ¯”' å¯¹æ¯”è¡¨"""
    
    # 1. å‡†å¤‡æ•°æ®
    df_report = df_source.copy()
    
    # === å…³é”®ä¿®æ”¹ï¼šå°†å†å²ç´¯è®¡å­—æ®µåŒ…å«åœ¨ sum_cols ä¸­ï¼Œä»¥ä¾¿å®ƒä»¬åœ¨åˆ†ç»„æ±‚å’Œåä¸ä¼šä¸¢å¤± ===
    # æ³¨æ„ï¼šè¿™é‡Œçš„æ±‚å’Œåªæ˜¯ä¸ºäº†ç¡®ä¿è¿™äº›åˆ—åœ¨ df_last_sum/df_current_sum ä¸­å­˜åœ¨ã€‚
    # å¯¹äºå†å²æ•°æ®ï¼Œæˆ‘ä»¬æ›´å…³å¿ƒæœŸæœ«å€¼ï¼Œè€Œä¸æ˜¯æœŸå†…åŠ æ€»ã€‚
    # å†å²æ¶ˆè€—(U)å’Œå†å²å……æå·®(U)æ˜¯å”¯ä¸€éœ€è¦è¢«ä¿ç•™ä½†ä¸éœ€è¦è¢«åŠ æ€»çš„å­—æ®µ
    sum_cols = [col for col in df_report.columns if col not in group_key and col != 'æ—¥æœŸ' and not df_report[col].dtype == object]
    
    today = date.today()
    
    if period_type == 'å‘¨':
        # è®¡ç®—æœ¬æœŸå’Œä¸ŠæœŸæ—¥æœŸèŒƒå›´
        end_of_current = today - timedelta(days=today.weekday()) - timedelta(days=1)
        start_of_current = end_of_current - timedelta(days=6)
        end_of_last = start_of_current - timedelta(days=1)
        start_of_last = end_of_last - timedelta(days=6)
        
        period_col = 'å‘¨æœŸ'
        period_name = 'å‘¨'
        date_format = '%m/%d'
    else: # æœˆ
        # è®¡ç®—æœ¬æœŸå’Œä¸ŠæœŸæ—¥æœŸèŒƒå›´ (è¿‘30å¤© vs. å†å‰30å¤©)
        end_of_current = today - timedelta(days=1)
        start_of_current = end_of_current - timedelta(days=29)
        end_of_last = start_of_current - timedelta(days=1)
        start_of_last = end_of_last - timedelta(days=29)
        
        period_col = 'æœˆä»½'
        period_name = 'æœˆ'
        date_format = '%m/%d'
        
    # --- é˜¶æ®µä¸€ï¼šç”Ÿæˆ äº§å“XXæ€»æ±‡è¡¨ (ç´¯ç§¯æ—¥æœŸ) ---
    sheet_total_name = f'äº§å“{period_name}æ€»æ±‡'
    
    # ç­›é€‰æœ¬æœŸå’Œä¸ŠæœŸæ•°æ®
    df_current_period = df_source[(df_source['æ—¥æœŸ'] >= start_of_current) & (df_source['æ—¥æœŸ'] <= end_of_current)].copy()
    df_last_period = df_source[(df_source['æ—¥æœŸ'] >= start_of_last) & (df_source['æ—¥æœŸ'] <= end_of_last)].copy()

    # åˆå¹¶ä¸¤æœŸæ•°æ®å¹¶æ±‚å’Œ (å‘¨æŠ¥æ€»æ±‡å°±æ˜¯æ±‚å’Œ)
    df_total = pd.concat([df_current_period, df_last_period])
    # ç¡®ä¿æ—¥æœŸåˆ—ç”¨äºæœ€ç»ˆå±•ç¤ºï¼Œæ‰€ä»¥è¦å…ˆåˆ†ç»„æ±‚å’Œ
    df_total_grouped = df_total.groupby(['æ—¥æœŸ', group_key])[sum_cols].sum().reset_index()
    
    # é‡æ–°è®¡ç®—è¡ç”ŸæŒ‡æ ‡
    df_total_grouped = calculate_metrics(df_total_grouped)
    
    # ç¡®ä¿æœ€ç»ˆå­—æ®µéƒ½å­˜åœ¨ï¼Œå¹¶é€‰æ‹©å­—æ®µ
    for col in final_cols:
        if col not in df_total_grouped.columns:
            df_total_grouped[col] = 0
            
    # è¾“å‡ºæ€»æ±‡è¡¨
    df_total_grouped[final_cols].to_excel(writer, sheet_name=sheet_total_name, index=False)
    print(f"{sheet_total_name} (ç´¯ç§¯æ—¥æœŸ) å·²ç”Ÿæˆ...")

    # --- é˜¶æ®µäºŒï¼šç”Ÿæˆ äº§å“XXæŠ¥è¡¨ (å¯¹æ¯”ç¯æ¯”) ---
    sheet_comp_name = f'äº§å“{period_name}æŠ¥è¡¨'
    
    # === å…³é”®ä¿®å¤ï¼šåŠ¨æ€è®¾ç½® comp_cols çš„ç¬¬ä¸€ä¸ªå‘¨æœŸåˆ— ===
    comp_cols = [period_col, 'å§‹æ—¥-æœ«æœŸ'] + [col for col in final_cols if col not in ['æ—¥æœŸ', group_key, 'è¾…åŠ©åˆ—']]
    
    # æ‰¾åˆ°æ‰€æœ‰éœ€è¦å‚ä¸åˆå¹¶çš„æŒ‡æ ‡åˆ—
    metrics_cols = [col for col in comp_cols if col not in [period_col, 'å§‹æ—¥-æœ«æœŸ']]
    
    # 1. è®¡ç®—ä¸ŠæœŸæ€»è®¡
    df_last_sum = df_last_period.groupby(group_key)[sum_cols].sum().reset_index()
    df_last_sum = calculate_metrics(df_last_sum)
    
    # === å…³é”®ä¿®å¤ç‚¹ 1: å¼ºåˆ¶ reindex ç¡®ä¿æ‰€æœ‰æŒ‡æ ‡åˆ—éƒ½å­˜åœ¨äº df_last_sum ä¸­ ===
    df_last_sum = df_last_sum.reindex(columns=df_last_sum.columns.tolist() + [col for col in metrics_cols if col not in df_last_sum.columns], fill_value=0)
    
    df_last_sum[period_col] = 'ä¸Š' + period_name
    df_last_sum['å§‹æ—¥-æœ«æœŸ'] = f"{start_of_last.strftime(date_format)}-{end_of_last.strftime(date_format)}"
    
    # 2. è®¡ç®—æœ¬æœŸæ€»è®¡
    df_current_sum = df_current_period.groupby(group_key)[sum_cols].sum().reset_index()
    df_current_sum = calculate_metrics(df_current_sum)
    
    # === å…³é”®ä¿®å¤ç‚¹ 2: å¼ºåˆ¶ reindex ç¡®ä¿æ‰€æœ‰æŒ‡æ ‡åˆ—éƒ½å­˜åœ¨äº df_current_sum ä¸­ ===
    df_current_sum = df_current_sum.reindex(columns=df_current_sum.columns.tolist() + [col for col in metrics_cols if col not in df_current_sum.columns], fill_value=0)
    
    df_current_sum[period_col] = 'æœ¬' + period_name
    df_current_sum['å§‹æ—¥-æœ«æœŸ'] = f"{start_of_current.strftime(date_format)}-{end_of_current.strftime(date_format)}"
    
    # 3. åˆ›å»ºç¯æ¯”è¡Œ
    df_combined = pd.merge(
        df_current_sum.drop([period_col, 'å§‹æ—¥-æœ«æœŸ'], axis=1), 
        df_last_sum.drop([period_col, 'å§‹æ—¥-æœ«æœŸ'], axis=1), 
        on=group_key, 
        suffixes=('_current', '_last')
    )

    df_comp = pd.DataFrame()
    for col in comp_cols:
        if col in [period_col, 'å§‹æ—¥-æœ«æœŸ']: # ä½¿ç”¨åŠ¨æ€çš„ period_col
            continue

        col_current = f'{col}_current'
        col_last = f'{col}_last'
        
        # å¦‚æœåˆ—ä¾ç„¶ç¼ºå¤±ï¼Œèµ‹å€¼ç©ºå­—ç¬¦ä¸²
        if col_current not in df_combined.columns or col_last not in df_combined.columns:
            df_comp[col] = ''
            continue
            
        if col in ['æ€»æ¶ˆè€—(U)', 'å……å€¼é‡‘é¢(U)', 'æç°é‡‘é¢(U)', 'å……å‡æ(U)', 'å†å²æ¶ˆè€—(U)', 'å†å²å……æå·®(U)', 'æ–°å¢ç”¨æˆ·æ•°', 'å……å€¼äººæ•°', 'é¦–å­˜äººæ•°']:
            # ç»å¯¹å€¼æŒ‡æ ‡ï¼šè®¡ç®—ç™¾åˆ†æ¯”ç¯æ¯” (æœ¬æœŸ-ä¸ŠæœŸ)/ä¸ŠæœŸ
            df_comp[col] = np.divide(
                df_combined[col_current] - df_combined[col_last], 
                df_combined[col_last]
            ).replace([np.inf, -np.inf], 0).apply(lambda x: f'{x:.1%}')
        elif col in ['æ³¨å†Œæˆæœ¬', 'é¦–å……æˆæœ¬', 'ç›ˆä½™ç‡(%)', 'é¦–å­˜ä»˜è´¹ç‡(%)', 'é¦–å­˜ç›ˆä½™ç‡(%)', 'æ–°å¢ä»˜è´¹ç‡(%)', 'è€ç”¨æˆ·ä»˜è´¹ç‡(%)', 'è€ç”¨æˆ·ç›ˆä½™ç‡(%)', 'ä»˜è´¹ç‡(%)', 'æ¬¡æ—¥å¤å……ç‡(%)', '3æ—¥å¤å……ç‡(%)', '7æ—¥å¤å……ç‡(%)', '15æ—¥å¤å……ç‡(%)', '30æ—¥å¤å……ç‡(%)', 'è£‚å˜ç‡']:
            # ç™¾åˆ†æ¯”/æˆæœ¬æŒ‡æ ‡ï¼šè®¡ç®—æ•°å·®ç¯æ¯” (æœ¬æœŸ - ä¸ŠæœŸ)
            df_comp[col] = (df_combined[col_current] - df_combined[col_last]).replace([np.inf, -np.inf], 0).round(2)
        elif col in ['é¦–å­˜ARPPU', 'æ–°å¢ARPPU', 'è€ç”¨æˆ·ARPPU', 'ARPPU', 'LTV-7å¤©', 'LTV-15å¤©', 'LTV-30å¤©', 'è€ç”¨æˆ·å……å‡æ(U)']:
             # è´§å¸/æ•°å€¼æŒ‡æ ‡ï¼šè®¡ç®—æ•°å·®ç¯æ¯” (æœ¬æœŸ - ä¸ŠæœŸ)
            df_comp[col] = (df_combined[col_current] - df_combined[col_last]).replace([np.inf, -np.inf], 0).round(2)
        else:
            df_comp[col] = ''
    
    df_comp[period_col] = 'ç¯æ¯”'
    df_comp['å§‹æ—¥-æœ«æœŸ'] = f'æœ¬{period_name}-ä¸Š{period_name}'

    # 4. åˆå¹¶æœ€ç»ˆå¯¹æ¯”æŠ¥è¡¨ (ä¸ŠæœŸã€æœ¬æœŸã€ç¯æ¯”)
    final_comp = pd.concat([df_last_sum[comp_cols], df_current_sum[comp_cols], df_comp[comp_cols]], ignore_index=True)
    
    final_comp.to_excel(writer, sheet_name=sheet_comp_name, index=False)
    print(f"{sheet_comp_name} (å¯¹æ¯”ç¯æ¯”) å·²ç”Ÿæˆ...")

# ==================== ä¸»å‡½æ•° ====================

def main():
    print("--- ç»ˆææŠ¥è¡¨ç”Ÿæˆå™¨ (å…¨è‡ªåŠ¨ä¸‰ç»´åº¦ç‰ˆ) å¼€å§‹è¿è¡Œ ---")
    
    # --- 1. è‡ªåŠ¨è¯»å–æ‰€æœ‰åœ¨çº¿å’Œæœ¬åœ°æ•°æ®æº ---
    df_spend = get_spend_data_from_google_sheet(SPEND_SHEET_URL)
    # å‡è®¾æ¸ é“æŠ¥è¡¨åŒ…å« 'æ—¥æœŸ', 'äº§å“', 'éƒ¨é—¨', 'æ¸ é“æ¥æº' ä»¥åŠæ‰€æœ‰æ•°å€¼æŒ‡æ ‡
    df_channel = read_source_file('download_æ¸ é“æŠ¥è¡¨_*.csv') 
    df_ops = read_source_file('download_è¿è¥æŠ¥è¡¨_*.csv') 
    df_ltv = read_source_file('download_æ–°å¢ç”¨æˆ·LTV_*.csv')
    df_retention = read_source_file('download_ç”¨æˆ·ç•™å­˜_*.csv')
    
    # --- 2. æ•°æ®é¢„å¤„ç†å’Œåˆå¹¶ ---
    print("\n--- å¼€å§‹æ•°æ®é¢„å¤„ç†å’Œåˆå¹¶ ---")
    # æ¸ é“æŠ¥è¡¨æ˜¯åŸºç¡€æ•°æ®æºï¼Œå¦‚æœè¯»å–å¤±è´¥ï¼Œç›´æ¥é€€å‡º
    if df_channel is None or df_channel.empty: 
        print("[è‡´å‘½é”™è¯¯] æ¸ é“æŠ¥è¡¨æ˜¯åŸºç¡€æ•°æ®æºï¼Œè¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨ä¸”èƒ½è¢«æ­£ç¡®è¯»å–ã€‚"); return

    # åŸºç¡€æ•°æ®å¤„ç†ï¼Œç¡®ä¿æ—¥æœŸå’Œåˆ†ç»„é”®æ˜¯æ­£ç¡®çš„ç±»å‹
    df_channel['æ—¥æœŸ'] = pd.to_datetime(df_channel['æ—¥æœŸ']).dt.date
    # ç¡®ä¿åˆ†ç»„å­—æ®µå­˜åœ¨ï¼Œå¦åˆ™æŠ¥è¡¨æ— æ³•ç”Ÿæˆ
    if 'äº§å“' not in df_channel.columns: df_channel['äº§å“'] = 'æœªåˆ†ç±»äº§å“'
    if 'éƒ¨é—¨' not in df_channel.columns: df_channel['éƒ¨é—¨'] = 'æœªåˆ†ç±»éƒ¨é—¨'
    if 'æ¸ é“æ¥æº' not in df_channel.columns: df_channel['æ¸ é“æ¥æº'] = 'æœªåˆ†ç±»æ¸ é“'
    
    # ä»¥æ¸ é“æŠ¥è¡¨ä¸ºåŸºç¡€ï¼Œä¿ç•™æ‰€æœ‰ç»´åº¦å­—æ®µ
    base_df = df_channel.copy()
    
    # åˆå¹¶è¾…åŠ©æŠ¥è¡¨
    dfs_to_merge = [
        (df_ops, 'è¿è¥æŠ¥è¡¨', ['æ—¥æœŸ']), 
        (df_ltv, 'LTVæŠ¥è¡¨', ['æ—¥æœŸ']), 
        (df_retention, 'ç•™å­˜æŠ¥è¡¨', ['æ—¥æœŸ']), 
        (df_spend, 'æ¶ˆè€—æŠ¥è¡¨', ['æ—¥æœŸ']) # æ¶ˆè€—è¡¨åªåˆå¹¶æ—¥æœŸç»´åº¦
    ]
    
    for df, name, on_cols in dfs_to_merge:
        if df is not None and not df.empty:
            if 'æ—¶é—´' in df.columns and 'æ—¥æœŸ' not in df.columns: df.rename(columns={'æ—¶é—´': 'æ—¥æœŸ'}, inplace=True)
            if 'æ—¥æœŸ' not in df.columns: continue
            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ']).dt.date
            
            # åˆå¹¶æ•°æ®
            # ä»…åˆå¹¶è¾…åŠ©è¡¨ä¸­æœ‰ï¼Œä½†åŸºç¡€è¡¨ä¸­æ²¡æœ‰çš„åˆ—
            cols_to_use = df.columns.difference(base_df.columns).tolist() + on_cols
            base_df = pd.merge(base_df, df[cols_to_use], on='æ—¥æœŸ', how='left', suffixes=(None, '_y'))
            # æ¸…ç†åˆå¹¶è¿‡ç¨‹ä¸­äº§ç”Ÿçš„å†—ä½™åˆ—
            base_df.drop([col for col in base_df.columns if '_y' in str(col)], axis=1, inplace=True)

    base_df.fillna(0, inplace=True)

    # --- 3. ç”Ÿæˆæœ€ç»ˆExcel ---
    print("\n--- å¼€å§‹ç”Ÿæˆä¸‰ç»´åº¦æ—¥æŠ¥ã€å‘¨æŠ¥ã€æœˆæŠ¥ ---")
    today = date.today()
    yesterday = today - timedelta(days=1)
    
    # å®šä¹‰æ—¶é—´èŒƒå›´
    
    # æ—¥æŠ¥
    df_daily = base_df[base_df['æ—¥æœŸ'] == yesterday].copy()
    
    # å‘¨æŠ¥ (æœ€è¿‘7å¤©)
    end_of_week = today - timedelta(days=today.weekday()) - timedelta(days=1)
    start_of_week = end_of_week - timedelta(days=6)
    df_weekly = base_df[(base_df['æ—¥æœŸ'] >= start_of_week) & (base_df['æ—¥æœŸ'] <= end_of_week)].copy()
    
    # æœˆæŠ¥ (æœ€è¿‘30å¤©)
    end_of_month = today - timedelta(days=1)
    start_of_month = end_of_month - timedelta(days=29)
    df_monthly = base_df[(base_df['æ—¥æœŸ'] >= start_of_month) & (base_df['æ—¥æœŸ'] <= end_of_month)].copy()
    
    # æ ¸å¿ƒæŠ¥è¡¨é…ç½®åˆ—è¡¨
    REPORT_CONFIGS = [
        # (æ•°æ®æº, åˆ†ç»„é”®, æœ€ç»ˆåˆ—, æ—¶é—´å‘¨æœŸ, Sheetåç§°)
        # äº§å“æ€»æ±‡è¡¨
        (df_daily, ['äº§å“'], PRODUCT_COLS, 'æ—¥æŠ¥', 'äº§å“-æ—¥æŠ¥'),
        (df_weekly, ['äº§å“'], PRODUCT_COLS, 'å‘¨æŠ¥æ€»æ±‡', 'äº§å“-å‘¨æŠ¥æ€»æ±‡'),
        (df_monthly, ['äº§å“'], PRODUCT_COLS, 'æœˆæŠ¥æ€»æ±‡', 'äº§å“-æœˆæŠ¥æ€»æ±‡'),
        # éƒ¨é—¨æ€»æ±‡è¡¨
        (df_daily, ['éƒ¨é—¨'], DEPT_COLS, 'æ—¥æŠ¥', 'éƒ¨é—¨-æ—¥æŠ¥'),
        (df_weekly, ['éƒ¨é—¨'], DEPT_COLS, 'å‘¨æŠ¥æ€»æ±‡', 'éƒ¨é—¨-å‘¨æŠ¥æ€»æ±‡'),
        (df_monthly, ['éƒ¨é—¨'], DEPT_COLS, 'æœˆæŠ¥æ€»æ±‡', 'éƒ¨é—¨-æœˆæŠ¥æ€»æ±‡'),
        # æ¸ é“æ€»æ±‡è¡¨
        (df_daily, ['éƒ¨é—¨', 'æ¸ é“æ¥æº'], CHANNEL_COLS, 'æ—¥æŠ¥', 'æ¸ é“-æ—¥æŠ¥'),
        (df_weekly, ['éƒ¨é—¨', 'æ¸ é“æ¥æº'], CHANNEL_COLS, 'å‘¨æŠ¥æ€»æ±‡', 'æ¸ é“-å‘¨æŠ¥æ€»æ±‡'),
        (df_monthly, ['éƒ¨é—¨', 'æ¸ é“æ¥æº'], CHANNEL_COLS, 'æœˆæŠ¥æ€»æ±‡', 'æ¸ é“-æœˆæŠ¥æ€»æ±‡'),
    ]

    with pd.ExcelWriter(OUTPUT_FILENAME, engine='xlsxwriter') as writer:
        
        # A. ç”Ÿæˆ 9 ä¸ªæ ‡å‡†æ€»æ±‡æŠ¥è¡¨
        for df, group_key, final_cols, time_period, sheet_name in REPORT_CONFIGS:
            if not df.empty:
                generate_summary_sheet(df, group_key, final_cols, time_period, sheet_name, writer)

        # B. ç”Ÿæˆ äº§å“å‘¨æŠ¥/æœˆæŠ¥ å¯¹æ¯”è¡¨ (ç‰¹æ®Šè¦æ±‚)
        if not df_weekly.empty:
            generate_comparison_sheets(df_weekly, 'äº§å“', PRODUCT_COLS, writer, period_type='å‘¨')
        if not df_monthly.empty:
            generate_comparison_sheets(df_monthly, 'äº§å“', PRODUCT_COLS, writer, period_type='æœˆ')
            
    print("\n" + "="*50)
    print(f"ğŸ‰ ç»ˆæä¸‰ç»´åº¦æŠ¥è¡¨ç”ŸæˆæˆåŠŸï¼è¯·åœ¨å½“å‰æ–‡ä»¶å¤¹æŸ¥çœ‹æ–‡ä»¶: {OUTPUT_FILENAME}")
    print("="*50)

if __name__ == '__main__':
    main()
